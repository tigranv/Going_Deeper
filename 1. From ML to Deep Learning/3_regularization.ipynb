{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "kR-4eNdK6lYS"
   },
   "source": [
    "Deep Learning\n",
    "=============\n",
    "\n",
    "Assignment 3\n",
    "------------\n",
    "\n",
    "Previously in `2_fullyconnected.ipynb`, you trained a logistic regression and a neural network model.\n",
    "\n",
    "The goal of this assignment is to explore regularization techniques."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "cellView": "both",
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "JLpLa8Jt7Vu4"
   },
   "outputs": [],
   "source": [
    "# These are all the modules we'll be using later. Make sure you can import them\n",
    "# before proceeding further.\n",
    "from __future__ import print_function\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from six.moves import cPickle as pickle\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "1HrCK6e17WzV"
   },
   "source": [
    "First reload the data we generated in `1_notmnist.ipynb`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "cellView": "both",
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "output_extras": [
      {
       "item_id": 1
      }
     ]
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 11777,
     "status": "ok",
     "timestamp": 1449849322348,
     "user": {
      "color": "",
      "displayName": "",
      "isAnonymous": false,
      "isMe": true,
      "permissionId": "",
      "photoUrl": "",
      "sessionId": "0",
      "userId": ""
     },
     "user_tz": 480
    },
    "id": "y3-cj1bpmuxc",
    "outputId": "e03576f1-ebbe-4838-c388-f1777bcc9873"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set (200000, 28, 28) (200000,)\n",
      "Validation set (10000, 28, 28) (10000,)\n",
      "Test set (10000, 28, 28) (10000,)\n"
     ]
    }
   ],
   "source": [
    "pickle_file = 'all_data/notMNIST.pickle'\n",
    "\n",
    "with open(pickle_file, 'rb') as f:\n",
    "    save = pickle.load(f)\n",
    "    train_dataset = save['train_dataset']\n",
    "    train_labels = save['train_labels']\n",
    "    valid_dataset = save['valid_dataset']\n",
    "    valid_labels = save['valid_labels']\n",
    "    test_dataset = save['test_dataset']\n",
    "    test_labels = save['test_labels']\n",
    "    del save  # hint to help gc free up memory\n",
    "    print('Training set', train_dataset.shape, train_labels.shape)\n",
    "    print('Validation set', valid_dataset.shape, valid_labels.shape)\n",
    "    print('Test set', test_dataset.shape, test_labels.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "L7aHrm6nGDMB"
   },
   "source": [
    "Reformat into a shape that's more adapted to the models we're going to train:\n",
    "- data as a flat matrix,\n",
    "- labels as float 1-hot encodings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "cellView": "both",
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "output_extras": [
      {
       "item_id": 1
      }
     ]
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 11728,
     "status": "ok",
     "timestamp": 1449849322356,
     "user": {
      "color": "",
      "displayName": "",
      "isAnonymous": false,
      "isMe": true,
      "permissionId": "",
      "photoUrl": "",
      "sessionId": "0",
      "userId": ""
     },
     "user_tz": 480
    },
    "id": "IRSyYiIIGIzS",
    "outputId": "3f8996ee-3574-4f44-c953-5c8a04636582"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set (200000, 784) (200000, 10)\n",
      "Validation set (10000, 784) (10000, 10)\n",
      "Test set (10000, 784) (10000, 10)\n"
     ]
    }
   ],
   "source": [
    "image_size = 28\n",
    "num_labels = 10\n",
    "\n",
    "def reformat(dataset, labels):\n",
    "    dataset = dataset.reshape((-1, image_size * image_size)).astype(np.float32)\n",
    "    # Map 1 to [0.0, 1.0, 0.0 ...], 2 to [0.0, 0.0, 1.0 ...]\n",
    "    labels = (np.arange(num_labels) == labels[:,None]).astype(np.float32)\n",
    "    return dataset, labels\n",
    "\n",
    "train_dataset, train_labels = reformat(train_dataset, train_labels)\n",
    "valid_dataset, valid_labels = reformat(valid_dataset, valid_labels)\n",
    "test_dataset, test_labels = reformat(test_dataset, test_labels)\n",
    "print('Training set', train_dataset.shape, train_labels.shape)\n",
    "print('Validation set', valid_dataset.shape, valid_labels.shape)\n",
    "print('Test set', test_dataset.shape, test_labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "cellView": "both",
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "RajPLaL_ZW6w"
   },
   "outputs": [],
   "source": [
    "def accuracy(predictions, labels):\n",
    "    return (100.0 * np.sum(np.argmax(predictions, 1) == np.argmax(labels, 1)) / predictions.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "sgLbUAQ1CW-1"
   },
   "source": [
    "---\n",
    "Problem 1\n",
    "---------\n",
    "\n",
    "Introduce and tune L2 regularization for both logistic and neural network models. Remember that L2 amounts to adding a penalty on the norm of the weights to the loss. In TensorFlow, you can compute the L2 loss for a tensor `t` using `nn.l2_loss(t)`. The right amount of regularization should improve your validation / test accuracy.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 128\n",
    "\n",
    "graph = tf.Graph()\n",
    "with graph.as_default():\n",
    "\n",
    "    # Input data. For the training data, we use a placeholder that will be fed\n",
    "    # at run time with a training minibatch.\n",
    "    tf_train_dataset = tf.placeholder(tf.float32, shape=(batch_size, image_size * image_size))\n",
    "    tf_train_labels = tf.placeholder(tf.float32, shape=(batch_size, num_labels))\n",
    "    tf_valid_dataset = tf.constant(valid_dataset)\n",
    "    tf_test_dataset = tf.constant(test_dataset)\n",
    "    beta_regul = tf.placeholder(tf.float32)\n",
    "\n",
    "    # Variables.\n",
    "    weights = tf.Variable(tf.truncated_normal([image_size * image_size, num_labels]))\n",
    "    biases = tf.Variable(tf.zeros([num_labels]))\n",
    "\n",
    "    # Training computation.\n",
    "    logits = tf.matmul(tf_train_dataset, weights) + biases\n",
    "    loss = tf.reduce_mean( tf.nn.softmax_cross_entropy_with_logits(labels=tf_train_labels, logits=logits)\n",
    "                         ) + beta_regul * tf.nn.l2_loss(weights)\n",
    "\n",
    "    # Optimizer.\n",
    "    optimizer = tf.train.GradientDescentOptimizer(0.5).minimize(loss)\n",
    "\n",
    "    # Predictions for the training, validation, and test data.\n",
    "    train_prediction = tf.nn.softmax(logits)\n",
    "    valid_prediction = tf.nn.softmax(tf.matmul(tf_valid_dataset, weights) + biases)\n",
    "    test_prediction = tf.nn.softmax(tf.matmul(tf_test_dataset, weights) + biases)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialized\n",
      "Minibatch loss at step 0: 48.788288\n",
      "Minibatch accuracy: 14.1%\n",
      "Validation accuracy: 16.4%\n",
      "Minibatch loss at step 500: 0.757698\n",
      "Minibatch accuracy: 85.9%\n",
      "Validation accuracy: 80.9%\n",
      "Minibatch loss at step 1000: 0.798442\n",
      "Minibatch accuracy: 78.9%\n",
      "Validation accuracy: 80.8%\n",
      "Minibatch loss at step 1500: 0.554608\n",
      "Minibatch accuracy: 83.6%\n",
      "Validation accuracy: 81.1%\n",
      "Minibatch loss at step 2000: 0.651663\n",
      "Minibatch accuracy: 88.3%\n",
      "Validation accuracy: 80.9%\n",
      "Minibatch loss at step 2500: 0.676383\n",
      "Minibatch accuracy: 82.8%\n",
      "Validation accuracy: 80.5%\n",
      "Minibatch loss at step 3000: 0.805645\n",
      "Minibatch accuracy: 80.5%\n",
      "Validation accuracy: 81.3%\n",
      "Test accuracy: 88.5%\n"
     ]
    }
   ],
   "source": [
    "num_steps = 3001\n",
    "\n",
    "with tf.Session(graph=graph) as session:\n",
    "    tf.global_variables_initializer().run()\n",
    "    print(\"Initialized\")\n",
    "    for step in range(num_steps):\n",
    "            # Pick an offset within the training data, which has been randomized.\n",
    "            # Note: we could use better randomization across epochs.\n",
    "            offset = (step * batch_size) % (train_labels.shape[0] - batch_size)\n",
    "            # Generate a minibatch.\n",
    "            batch_data = train_dataset[offset:(offset + batch_size), :]\n",
    "            batch_labels = train_labels[offset:(offset + batch_size), :]\n",
    "            # Prepare a dictionary telling the session where to feed the minibatch.\n",
    "            # The key of the dictionary is the placeholder node of the graph to be fed,\n",
    "            # and the value is the numpy array to feed to it.\n",
    "            feed_dict = {tf_train_dataset : batch_data, tf_train_labels : batch_labels, beta_regul : 0.01}\n",
    "            _, l, predictions = session.run([optimizer, loss, train_prediction], feed_dict=feed_dict)\n",
    "            if (step % 500 == 0):\n",
    "                print(\"Minibatch loss at step %d: %f\" % (step, l))\n",
    "                print(\"Minibatch accuracy: %.1f%%\" % accuracy(predictions, batch_labels))\n",
    "                print(\"Validation accuracy: %.1f%%\" % accuracy(valid_prediction.eval(), valid_labels))\n",
    "    print(\"Test accuracy: %.1f%%\" % accuracy(test_prediction.eval(), test_labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The L2 regularization introduces a new meta parameter that should be tuned. Since I do not have any idea of what should be the right value for this meta parameter, I will plot the accuracy by the meta parameter value (in a logarithmic scale)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialized for reg = 0.0001\n",
      "Initialized for reg = 0.00012589254117941674\n",
      "Initialized for reg = 0.00015848931924611142\n",
      "Initialized for reg = 0.0001995262314968881\n",
      "Initialized for reg = 0.0002511886431509582\n",
      "Initialized for reg = 0.00031622776601683826\n",
      "Initialized for reg = 0.00039810717055349773\n",
      "Initialized for reg = 0.000501187233627273\n",
      "Initialized for reg = 0.0006309573444801943\n",
      "Initialized for reg = 0.0007943282347242829\n",
      "Initialized for reg = 0.001000000000000002\n",
      "Initialized for reg = 0.00125892541179417\n",
      "Initialized for reg = 0.0015848931924611173\n",
      "Initialized for reg = 0.001995262314968885\n",
      "Initialized for reg = 0.0025118864315095872\n",
      "Initialized for reg = 0.003162277660168389\n",
      "Initialized for reg = 0.0039810717055349856\n",
      "Initialized for reg = 0.00501187233627274\n",
      "Initialized for reg = 0.006309573444801955\n",
      "Initialized for reg = 0.007943282347242847\n"
     ]
    }
   ],
   "source": [
    "regul_values = [pow(10, i) for i in np.arange(-4, -2, 0.1)]\n",
    "accuracy_val = []\n",
    "\n",
    "for beta in regul_values:\n",
    "    with tf.Session(graph=graph) as session:\n",
    "        tf.global_variables_initializer().run()\n",
    "        print(\"Initialized for reg = {0}\".format(beta))\n",
    "        for step in range(num_steps):\n",
    "                offset = (step * batch_size) % (train_labels.shape[0] - batch_size)\n",
    "                batch_data = train_dataset[offset:(offset + batch_size), :]\n",
    "                batch_labels = train_labels[offset:(offset + batch_size), :]\n",
    "                feed_dict = {tf_train_dataset : batch_data, tf_train_labels : batch_labels, beta_regul : beta}\n",
    "                _, l, predictions = session.run([optimizer, loss, train_prediction], feed_dict=feed_dict)\n",
    "        accuracy_val.append(accuracy(test_prediction.eval(), test_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.semilogx(regul_values, accuracy_val)\n",
    "plt.grid(True)\n",
    "plt.title('Test accuracy by regularization (logistic)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX0AAAEICAYAAACzliQjAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMi4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvhp/UCwAAIABJREFUeJzt3Xl8XHd57/HPI8naZUmWLTu25D2bkzhO7IATINgkkFAgaS9L0yZlaxpS4ALpLdBelhQKvHIplPZeCjRNQglLnJWEJilNKDYEnDjxFsfZvcqOHe+bdmn03D/Ob8aj8UgabdZ45vt+vealmbPNc2ZGz/md5/zOOebuiIhIfigY6wBEROTkUdIXEckjSvoiInlESV9EJI8o6YuI5BElfRGRPKKkL1nPzErNzM2sYaxjGSwze8rMrhvG/JvN7OIRjqnEzJrNbOpILjdp+d8xsxvD8yvNbNMILHPIMZvZV8zsuxlM9z0z+/CQAjyFKOmPgPBjjD96zKwt6fW1w1jusBKGnPrcfY67PzmcZaT+jty9w90r3X3X8CM84b2mAe8D7hjJ5WYac7qNjLvf7O6fzOBtvgn8nZkVDifWbKekPwLCj7HS3SuBJuA9ScN+OtbxjRYzKxrrGIYrW9chW+PKwEeBB929c6wDGSx33wbsAN45xqGMKiX9k8DMCs3sS2a2xcz2m9lPzawmjKsws2VmdtDMDpvZKjOrNbNvAxcBt4U9hm+nWW6Rmd1vZnvCvMvN7Myk8RVm9n/NbIeZHTGz38STiZktCS3AI2bWZGZ/Gob3ahWa2Y1m9qvwPF5m+Usz2wxsDMO/b2Y7zeyomT1tZotTYrw5rPtRM3vGzKaY2e1m9vWU9Xk8Xhbowx+a2TYz22dmX7dIeVju6UnLaTCz1vhnnPIeN5rZr83sX8zsEPA3YfjHzOzl8D08Elqs8XneZWavhs/4n5I/IzO7xcxuS5r2LDPrThd8GLcivMc+M/uRmVUljX/dzP7azJ4HjiYNe3P4DSXvUbaE72KKmU0ys/8MyzxoZg+Z2Wlh/hN+R5ZSLjOzCWb2szD/VjP7nJlZ0uf13+F3dNiictPl/XxH7wR+09dIMzvPzJ4Iy9pgZu9MGlcf1uNo+IxvSfPbi8d8tZm9ZGbHwu/7U2ZWB/wcmJ30OdWl+Y7S/vaDFcC7+lm/U5+76zGCD2AbcHnKsL8BngCmAqXAvwM/DOM+DdwHlAFFRP+gFWHcU8B1/bxXEfAhoDIs9/vAU0njbwceA6YAhcBbwt+5QDPw3rCMScD56d4TuBH4VXheCjjwCFADlIXhHwRqgXHAF4haS+PCuC8B68J7FgAXhHkvBbYCFqabCrQCE9KsZ/x9/yvMOwvYEo+TqJTwlaTpPw/c28dndiPQDfxF+CzKgGuAF4Ezwjp8DVgepp8SPqt3h3GfA7qS3vsW4Lak5Z8FdCe9fipp2rOAtwHFYblPAbckTfs68Ez4LMqShr05zXr8I/CrsA6TgavDulQDDwHL0sWQ8nk2hNf3APeG39Hc8L1cm/R5dYXvuBC4CdjWz2/yGHBe0usrgU1J77sd+F/hs7wifLazwvgHgTvDeswHdnPiby8e8wHgDeF5HXBB6vslxZD4jujntx/G/ymwcqzzyGg+xjyAXHuQPulvBd6U9HoWUYIz4ONELaNz0yyr36SfZvopQE/4BxkX/lnPTDPdV4C7+lhGJkn/kn5isLBuZ4bX24Er+phuC/CW8PqvgQf6WGb8fZckDfsr4JHw/K3J/+jAc8BVfSzrRuCVlGHL40kuvI5/dpOBGwgbgDCuANjLEJJ+mliuAZ5Mev068Kcp05yQ9IkS8CbSbCDD+MXA7n6+00QCBUqAGDA7afyngV8mfV4bk8ZNCPPWpHnfwjBuZtKw5KT/9vB7sKTxPydqFJWG3+6MpHHfSvPbiyf9PcBHgKqUGAZK+n3+9sP49wAvZPo/dyo+VN4ZZWE3uRF4NOzSHiZq+RYQtVBuJ0r694USyTcswwNJoXTyrXjpBHiJKJnWAacRtWS2pJm1Edg8jNXakRLH34bSyBHgENE/6MSw7tPSvZdH/2F3AvFS0nXAjwfxvtuJWsQAvwUKzexiM1tAtO7/mWn8wAzgB0nfzz6ivYGG8B6J6d29B3htgDjTMrOpZnavmb0Wvq/bgIkDxJa6jDcA3wb+0N0PhmFVZnZHKFUcJdq7S11uX6YQ/RabkoZtJ/re4l5Pet4a/lamLsjdY0Qt/arUccFUoCl896nvNYXot7szaVx/n8UfErXWm0K5blE/0yYb6LdfBRzOcFmnJCX9URZ+4K8Bb3P3mqRHqbvv96hXwpfd/Syiksf7iVqAELVs+vMR4B3AUqLd+rPCcCPaNe4GZqeZbwcwp49ltgDlSa+npFut+BMzezvwP4E/Iiq9TADaiFpz8XXv673uBN5nZguJ/hkf6WO6uMak59OBXXDCBuTPiEobXf0sJ/Vz3QF8OOX7KXP3NUSfY6KrqJkV0DshZvJ5xf1DmP5cdx8PXE/0XfUXW0Ko0z8AXO/uG5NG/U2I8aKw3HekLLe/39HrRC3s6UnDpjPEDRuwgahMls6ulPdJfq/XieJM/mwb6YO7P+nu7ybaG3sMuCs+aoD4+vvtA5wNPDvAMk5pSvonxw+AW8ysERIHrN4Tnl9uZvNCMjlKlKhjYb49pE/acVVAO1F9s4KoFg1ASHp3Av9sZpPDgcA3h72IO4F3m9kfheGTzGx+mHU9USIuNbOzgA8PsG5VRKWQfUS16q8StfTjbgO+YWazLXKBhQOs7r4FeAH4IXC3D9zj4/NmVm1mM4FPAncnjbsT+ADwJ+H5YPwA+KKFg+AWHUh/bxj3C+CNZvYHFh0E/yui4xdx64GlZjbNzGqJjif0pYqonnzUzKaHZWXEzIqJSiH/6u4PpVluK3DYzCYCX0wZ3+fvyN07wnK/YdGB/zlE5Z2fZBpbikeJym3pPAEUmNlnwl7q24k2UPe6ezvwH8BXwm/vXKL6+glCnNeY2Xii394xev/P1JvZCXsiQX+/fULs/e0lnvKU9E+ObxIddPu1mR0DVgIXhnHTiA68HSPqDfMo0YE1gO8AHzSzQ2b2zTTLvZ0o2b5OVMf+Xcr4TxHtyq4j2jD8PVELfDPRgb//TVSOWQ2ckxRrUVjurQz8z/8fROWVzUSlpP1h3rhbiFrwvybaqP2AqI4c9yPgPAYu7RCW82yI997k2MI6vQwcc/enM1hWgrvfBXwXeCCUR9YT1Z9x991EG5L/G9atgeiz7kiK6WGijddTRAcj+/Jl4M3AEaJEe/8gwpwNvJFow5fci6eeqPY9keg7/h3RbyjZQL+jj4W/24m+p9uAoXY1/neiXlbFqSNCYn83UT/+A0QHo/84fHfxOKYS/X5uI2q9d6QuJ/hoiPcI0TGOD4XhzxJtqLeHct2ElBj6/O2b2QyiUl/q55dT4j0nRMaEmb0D+J67zx2BZf2M6CDc1waceOjvUUS0kX2PD/OkqVxlZv9IdLD8B8Nczj8Dpe7+sQEnHgFm9i/AGncf0RPLso2SvoyZ0Bp8APitu6drgQ5mWXOBtcDZ7j7UenRfy34n0d5ZB1GX1A8BczMoR8kghJKOE+01XUy0F/Un7v7LMQ0sx6i8I2Mi9LI5RFSP/pdhLuubRCWsr450wg/i5xTsBS4D/kgJf1RUE5ULW4hKd19Twh95aumLiOQRtfRFRPJI1l3UaeLEiT5z5syMp29paaGiomL0AhqGbI0tW+MCxTZUim3wsjUuGFpsa9as2e/ukwaccKxPCU59LFy40Adj+fLlg5r+ZMrW2LI1LnfFNlSKbfCyNS73ocUGrHZdhkFERJIp6YuI5BElfRGRPKKkLyKSR5T0RUTyiJK+iEgeUdIXEckjWXdylpwaDrd2smlvM6/ubeZAcwd1lSXUV5VQX1VK/fgS6iqKKSpUm0Ik2yjpn2I27DzMnU9uZ8r4UubUVzB7YiWzJ1VQVTpuxN/L3dnf3Mmre49FCX5PcyLR72/u6zLnETOoqyhmUlVp2BiUUD8+bBSSnk+qKqF0XEZ3hxSREaCkfwrZe7SdP//Ralo6uuno7iHWc/xiefVVJcyeVMHsSZXMmRRtCOZMrGRabRmFBal35OvN3dl9pJ1X9zbz6p5jbN4XJfhX9zZzpO34XQerSoqYO7mSpWdO4vTJlZxeX8Xc+komVZVwoKWTvUfb2Xusg73HOth3rIN9x9rZezR6/dLrR9nf3Nkr5sRyS4sSewne1s7vW15I7DFMqow2EJPHl47Khk0k3yjpnyK6Yj184mdraW7v5qFPvomZdRU0HWxl875mtuxrCX+beWTD7l6JuriogFl1FdFGIGwMtu/t5qXfbA4t96gV39IZS8xTWz6O0ydX8a75p3F6/fHkPnl8CdG9zk80raaMaTVl/a5DrMc51NoZNgTtiY3D3qPt7GvuYO/RDrYf7mH9U9tp7+o5Yf4zJ1dx8Zw6Lp5Tx+JZdVSXayMgMlhK+qeIb/7yJZ7Zdoh/vmYBZ0yuAmBufSVz63vfCtTdOdjSyZb9LWze25z4+9Lrx3jshT1JLe2XmDy+hLn1lbx/UWNiWafXV1JXWcJoKCwwJlaWMLGyhHmMTzvNihUreOtb38qxjm72Hg0bhWPt7DjYyqqtB1n2TBP/vnIbZnDu1GouCRuBi2ZOoKJEP2eRgWT0X2JmNwHXE93V5jngI8AlRPfmLAbWAH/u7t1p5v0Qx2/U/DV3/9EIxJ1XHn1uN//2xFY+dPEMrl4wrd9pzYy6yhLqKku4aGav24PS2d1D08EWfrPyad53xaVUl2VnS9nMGF86jvGl43pt1D4JdHTHeHbHEVZu3s+Tmw/ww99v419/u4WiAuP8xprERuDC6bU6ViCSxoBJ38ymEd1ge567t5nZPUR3qf8KcJm7v2JmXyW6hdztKfNOAG4GFhFtMNaY2S/c/dAIr0fO2ryvmc/dt4ELptfwhXfNG9ayiosKmFtfxc6awqxN+AMpKSrkDbMm8IZZE/jM5dDWGWPN9kOs3LyflZsP8L0Vm/l/v95EcVEBC6fXcsmcOi6ZW8f8hhrGqTeRSMblnSKgzMy6gHKi25l1uPsrYfzjwN+SkvSBK4DH3f0ggJk9DlxJdJd7GUBLRzc3/ngNxUUFfO/aCykuUtJKVVZcyJtPn8ibT58IwLH2Lp7ZdpCVmw6wcvMBvv34K3z7cSgvjjYWF8+u45I5E5k3dfyAB7hFclFGt0s0s08DXwfagMeA64BtwHvdfXW4a/3b3P28lPn+muhu9l8Lr78EtLn7t1KmuwG4AWDy5MkLly1blvEKNDc3U1lZOfCEY2A4sbk7/7qhg1W7Y3z2olLm1Y1cqSJXP7N0jnU6Lx2M8dLBGC8eiLGrJfq9lxfBWRMKObuukLMnFDKt0vo8SD1asY0kxTZ42RoXDC22pUuXrnH3RQNNl0l5pxa4GpgFHAbuBa4FrgG+Y2YlRBuCE+r5QLr/ohO2Mu5+K3ArwKJFi3zJkiUDhZWwYsUKBjP9yTSc2O58chtP7X6ez15xJh9fOjdr4hptoxHbe5Ke7z3azpNbDkR7Alv2s/bFNgAmVhazOOwFXDKnjhl15SdsBPLtcxsp2RpbtsYFoxtbJuWdy4Gt7r4PwMweAC5x958AbwnD3gGckWbencCSpNcNwIphxJsX1jYd4u8ffoHLzqrnL986Z6zDySn140u5esG0xAHxHQdbeXLLAZ7cfICVm/fz8IbdAJxWXcrFc45vBKYO0B1V5FSRSdJvAhabWTlReecyYLWZ1bv73tDS/zxR+SfVfwHfCHsLAO8gqv1LHw40d/CJn67ltOoy/vEDCyhQ3XlUNU4op3FCOR9Y1Ii7s2V/Cys3H+CpzQdY8fI+Hlj7GhCdh1Bb2Ml/H97IzIkVzJpYzoy6Chpry3WsRU4pAyZ9d19lZvcBa4lKOOuISjFfM7N3E1207fvu/msAM1sE3Oju17v7QTP7e+CZsLivxg/qyoliPc6nlq3jYEsnD3z8Ep18dJKZGXPCGc1/tngGPT3Oy3uOsXLzAdbvOMxzW1/nwXWvcazjeCWzwGBabRkz6yqYNbGCGXXaIEh2y6j3jrvfTNT1MtlnwyN12tVEffrjr+8A7hhGjHnjO4+/wu83HeCb75vPOVOrxzqcvFdQYJx92njOPi06kSx+4tjBlk62HWhl2/4Wth1oSTz/+doTNwgNteXMqCvvtUGYWVdBgzYIMkZ0CmOW+O8X9/Dd5Zu45qJGPrCocazDkT4kn/y2cEZtr3Hxs6Ez2SAUFhjTasoSG4SZdRXM1AZBTgIl/SzQdKCVm+5ez7nTxvN3V50z1uHIEI30BmHmxApm1pX32iA0TijXSWYyLEr6Y6y9K8aNP1mDmfH9axfq0gE5KrMNQgvb9rf22iCs235owA3CrIkV7GmJrrqqE85kIEr6Y8jd+dKDG3lh91F++OGLaJxQPtYhyRjovUHofb2kwWwQvrzyl9HVVMOF8+aGK6TOnFhOSZEaExJR0h8j7V0xPn//Bh5av4tPvW0uS8+qH+uQJAtlukF49Ik1FNU1sGlPMxtfO8Kjz+0mfrJ9YYExY0L58SupTq5k7qQq5tRXUF6sFJBv9I2PgV2H2/jYj9ewcdeR6IzbJToBSwYveYNwbOs4liw5OzGuvSvGln0tvLr3GJvD3c5e3dvMr1/aS3fSjWym1ZSFjUDYGNRHGwR1F85dSvon2eptB7nxJ2to7+rh3/5sEZfPmzzWIUkOKh1XyLyp45k3tfd9C7piPWw/0HL89pfhLmlPbj5AR/fxG9dMqipJKhFVhpJRFRMriwe8RpFkNyX9k+iup5v48kMbmVZTxrIbFjG3vmqsQ5I8M64wurz23Poqrjz3+PBYj/PaoTY27TvW617IqT2LqsvGJTYGUakouqva1OpSbQxOEUr6J0FXrIev/scL/Pip7Vx6xiT+3zUXaPdZskphgTG9rpzpdeW87azje5/uzp6jHWEjcCyxMXj8hT0se2ZHYrqK4kLmJG8Mwi02p6tzQtZR0u/HxteO8NNVTZxWXUrjhDIaa6PrtEyqLMn4mjgHmjv4y5+u5emtB/nYpbP53JVnqVudnDLMjCnVpUypLk3csyDuQHO0MYiXiDbva2blpgOJ6xVBdOOe+lJnwa61vTYG6lE0dpT0+9DS0c3Hf7qW3Ufa6Ir1vhp0SVEBDbVlnH3aeM5vqOG8hmrOnVZNZco9WrcfjfGF7/6efc0dfOePz+ePLmg4masgMqriB5HfOLuu1/Bj7V3RxiA8nnpxOxt2HuER9SjKCvp0+/CNR19kx6FWlv3FYs5vrGHnoVZ2HGpj58Ho77b9LaxrOpy4FK8ZzJlUyfxp1cxvqKawsICvP9XOhMpS7rvxYuY31IzxGomcHFWl47hgei0XTI9OQltRvoclS5bQ3hVj877mXhuE1B5FZjB3UiUXTK8Jy6jh9Poq7R2PICX9NH7zyj5+uqqJv3jLrEQrJn7wK9X+5g6e23mEDTuPsGHnYX776n4eWBft3s6tKeBnn3gT9VWlJzV+kWxUOq6Qc6ZWn3AxweQeRS+/3syzOw/z+At7uGf1TgAqS4o4v7GaCxqjjcCCxhrqKkvGYhVygpJ+iiOtXXzuvmc5vb6S//WOMwecfmJlCUvPqk+cXBU/8LX9QAtHt21QwhcZQLoeRe7O9gOtrNtxiHVNh1nXdJjv/2YzsbBHMKOunAsaj+8NnH3aeF2TKENK+im+/IuNHGju5LYPXjSk6+AkH/ha0aRdUpGhMLPo+kITKxLHwto6Y2zcdYR1TYdYu/0wKzcf4MH1u4DoONt506oTZaELp9cypVoNrnSU9JM8smE3D63fxU2Xn8F5DbqevUg2KSsu5KKZE7hoZnQ5Cndn95H2sCdwiHU7DvOjJ7fzb09sBaJbXl4wvSZRFjp3WrUuaIiSfsLeY+188cHnmN9QzceX6rIIItnOzJhaU8bUmjLeNf80ADq7e3hx99HERmBd02Eefe51AIoKjHlTxyfKQp2tPbh73p1UpqQf3LVqB4fburj3A+erNihyiiouKuD8xhrOb6zhw2HY/uYO1jcdZm1TdHzg3jU7+dGT2wG4Zc2vwkYg2hDMb6imqjS3T5xU0g8OtXZSWVKkSyOI5JiJlSVcPm9y4jpXsR7nlT3HuPtXq2gprWfdjsP890t7gajL6Bn1VVw443hZaM6kyoxPxjwVKOkHrZ3dVOikEJGcVxjufbykcRxLlpwPwJG2Lp4N5aB1Ow7x6HOvc9fT0WUmqkqKWDC9JlEWWtBYQ21F8ViuwrAoywUtnTEqSnSQRyQfVZeN49IzJnHpGZOA6CDxlnAC5rpQFvru8k3Er0o9a2JFr7LQmVOqTpmysJJ+0NLRTUWJPg4RiQ4Sz5lUyZxJlbxvYdRltKWjm+deO5LYECSfiFk6roD5DTWJ3kIXTq+hfnx2dhlVlgtaO2KUF6ulLyLpVZQUsXh2HYvDWfruzmuH2xInj63bcYgf/m4b/xrbAkQ3qEkuC50zdXxWdBlV0g9aOruZkqVbZhHJPmZGQ205DbXlvOf8qQB0dMd4ftfRXmWhR8L1ucYVGvOmVifKQhdOr6WhtuykdxlV0g9U3hGR4SopKuTCcEYwzAJg79H2xDkD65oOcfczO/j3ldsAmFhZzILG2kRvofkN1aOeh5TlAh3IFZHRUD++lCvOmcIV50wBoDvWw8t7jh0vCzUd4lcv7gHgrClV/PIzl45qPEr6QWtHt67jLSKjrqiwIHG10esWzwDgUEsn63cepjPpPsWj9v6j/g6ngJ4ep7UrpvKOiIyJ2opilp5Zf1Le69ToWDrK2rpiuEf3+RQRyWVK+kQ9dwDK1dIXkRynpE/URx+gUgdyRSTHZZT0zewmM3vezDaa2V1mVmpml5nZWjNbb2a/M7O5aeabaWZtYZr1ZvaDkV+F4WvuCC19HcgVkRw3YJYzs2nAp4B57t5mZvcA1wD/G7ja3V80s48DX4TE1UyTbXb3BSMY84hr7Yxa+rrgmojkukzLO0VAmZkVAeXALsCB8WF8dRh2Sjpe01d5R0Ry24BNW3d/zcy+BTQBbcBj7v6YmV0PPGpmbcBRYHEfi5hlZuvCNF909ydGKPYRc7ymr5a+iOQ2c/f+JzCrBe4H/hg4DNwL3Af8D+D/uPsqM/sscKa7X58ybwlQ6e4HzGwh8CBwjrsfTZnuBuAGgMmTJy9ctmxZxivQ3NxMZWVlxtOn89udXdyxsZNvvbWMiWUjd2x7JGIbDdkaFyi2oVJsg5etccHQYlu6dOkad1804ITu3u8DeD9we9LrDwLfJ6rVx4dNB17IYFkrgEX9TbNw4UIfjOXLlw9q+nTu+N0Wn/H5h/1gc8ewl5VsJGIbDdkal7tiGyrFNnjZGpf70GIDVvsAOdjdM6rpNwGLzazcosvBXQa8AFSb2RlhmrcDL6bOaGaTzKwwPJ8NnA5syeA9T6rEgVyVd0Qkx2VS019lZvcBa4FuYB1wK7ATuN/MeoBDwEcBzOwqotb8l4FLga+aWTcQA25094OjsibD0NzRzbhCo7hIpy2ISG7LqGnr7jcDN6cM/nl4pE77C+AX4fn9RMcDspoutiYi+UJNW6LLKqvnjojkAyV9oLWzW7dKFJG8oKQPNHfEdLE1EckLSvpENX1dVllE8oGSPvFbJaqlLyK5T0mfcFN0tfRFJA8o6RMO5KqlLyJ5QEkfaOlQl00RyQ95n/RjPU5bV0xdNkUkL+R90m8N19LXDVREJB8o6etiayKSR/I+6beE++NW6K5ZIpIHlPTDXbN0wTURyQdK+omavlr6IpL78j7pJw7kqqYvInkg75N+vLyjmr6I5AMl/XAgVzV9EckHSvrqsikieSTvk35roqWv8o6I5L68T/rNnd0UFxUwrjDvPwoRyQN5n+ladbE1EckjeZ/0W3R/XBHJI3mf9Fs7YrrYmojkjbxP+i2d3ZSrj76I5Akl/Y5u1fRFJG/kfdJv7dQNVEQkf+R90m/u6FZNX0TyRt4n/dbOmM7GFZG8kfdJv6VDB3JFJH/kddLvjvXQ0d2j8o6I5I28Tvrxi63pQK6I5Iu8TvrxG6ioy6aI5IuMkr6Z3WRmz5vZRjO7y8xKzewyM1trZuvN7HdmNrePef/WzDaZ2ctmdsXIhj88ifvjKumLSJ4YMOmb2TTgU8Aidz8XKASuAb4PXOvuC4CfAV9MM++8MO05wJXA98wsa2op8Ruo6P64IpIvMi3vFAFlZlYElAO7AAfGh/HVYViqq4Fl7t7h7luBTcAbhhfyyGnR/XFFJM+Yuw88kdmnga8DbcBj7n6tmb0FeDAMOwosdvejKfN9F3jK3X8SXt8O/Ke735cy3Q3ADQCTJ09euGzZsoxXoLm5mcrKyoynT7Zubzf/vLaDv7u4lJnVI9/aH05soylb4wLFNlSKbfCyNS4YWmxLly5d4+6LBpzQ3ft9ALXAr4FJwDiiRH8d8ADwxjDNZ4Hb0sz7L8B1Sa9vB97b3/stXLjQB2P58uWDmj7Zg+t2+ozPP+yb9h4b8jL6M5zYRlO2xuWu2IZKsQ1etsblPrTYgNU+QD5394zKO5cDW919n7t3hWT/JuB8d18VprkbuCTNvDuBxqTXDaQvA42J+IFc9d4RkXyRSdJvAhabWbmZGXAZ8AJQbWZnhGneDryYZt5fANeYWYmZzQJOB54egbhHRLzLpvrpi0i+GLCJ6+6rzOw+YC3QDawDbiVqxd9vZj3AIeCjAGZ2FVFPny+7+/Nmdg/RRqIb+IS7x0ZnVQYv0WVTZ+SKSJ7IKNu5+83AzSmDfx4eqdP+gqiFH3/9daKDwFmnpbOb0nEFFBbYWIciInJS5PUZubqBiojkm7xO+tENVJT0RSR/5HXSb+no1kFcEckr+Z30O1XeEZH8kt9JvyOmi62JSF7J66Tf2tmti62JSF7J66Tf0qH744pIfsn5pO/uLH95Lz09J15YrkUtfRHJMzmf9De+dpSP/PAZHnvh9RPGtaqmLyJ5JueT/pG2LgDWNR3uNbyzu4fOWI9a+iKSV3I+6ccvqvbszsNph6umLyL5JOeTfltXdFG1ja8d7VXXb+mMhlfsM9etAAAOXklEQVTojFwRySO5n/RDcm/u6GbL/pbE8NZwf9zyEpV3RCR/5HzSb+08fiXnDUklnuYOlXdEJP/kfNKPl3eKiwrYsPNIYniryjsikodyP+l3xigwOL+huldLv6VDd80SkfyT80k/fvnk+Q01PL/rKF2xHiA6MQt0f1wRyS85n/TburopHVfI/IZqOrp7eGXPMSDpVok6kCsieST3k35njPLiQuY31AAk6vqJfvqq6YtIHsn5jNcakv7MunLGlxbx6HO72bKvmV8+/zpmUDZOLX0RyR85l/Rf2HWUOfUVlBRFybytK0bpuELMjAum1/KbV/axautBFk6v5ca3zqFAN0UXkTySU0n/aHsXV333d3zjf5zHBxY1AsfLOwC3vPc8th9oZUFjDaVq4YtIHsqppN/aEaO7xznW3n18WGeMmvJxAJxWXcZp1WVjFZ6IyJjLqQO58e6YsZ6exLD2UN4REZEcS/rd4YJq3UkXVmtNKu+IiOS73Er68ZZ+LDnpd1OubpkiIkCOJf2u2Ikt/fauHpV3RESCnEr63T3xmn5I/rHo7lgq74iIRHIq6cdb+jGP/raGK2zqBCwRkUhOJf1ETT+09NvD5ZPL1NIXEQFyLeknyjqhpR+Svso7IiKRnEr6qf3040lf5R0RkUhGfRnN7CbgesCB54CPAI8DVWGSeuBpd//DNPPGwjwATe5+1XCD7kt3Su+d+F2zVN4REYkMmPTNbBrwKWCeu7eZ2T3ANe7+lqRp7gce6mMRbe6+YESiHUBq7522RHlH/fRFRCDz8k4RUGZmRUA5sCs+wsyqgLcBD458eIOT2k8/fs18lXdERCLm7gNPZPZp4OtAG/CYu1+bNO6DwFXu/r4+5u0G1gPdwC3ufsLGwcxuAG4AmDx58sJly5ZlvALNzc1UVlYC8PvXuvi35zq5eGohH5tfylO7uvnBhg6+8eYyplae/MMXybFlk2yNCxTbUCm2wcvWuGBosS1dunSNuy8acEJ37/cB1AK/BiYB44ha9Ncljf9P4L39zD81/J0NbAPm9Pd+Cxcu9MFYvnx54vndTzf5jM8/7J/82Vp3d79r1Xaf8fmH/bVDrYNa5khJji2bZGtc7optqBTb4GVrXO5Diw1Y7QPkc3fPqLxzObDV3fe5exfwAHAJgJnVAW8AHulno7Ir/N0CrAAuyOA9h6Srp3fvnTadnCUi0ksmSb8JWGxm5WZmwGXAi2Hc+4GH3b093YxmVmtmJeH5ROBNwAvDDzu9RO+dlH766r0jIhIZMOm7+yrgPmAtUdfLAuDWMPoa4K7k6c1skZndFl6eDaw2s2eB5UQ1/VFL+l2xE3vvFBiUFOXU6QgiIkOWUV9Gd78ZuDnN8CVphq0m6tOPu68EzhteiJlLvZ5+W1eMsnB/XBERybEzclOvvdPaGaNMffRFRBJyKukf76cfDuR2dlNWnFOrKCIyLDmVEePJPn6L3LauGOXj1NIXEYnLraSf0tKPyjvquSMiEpdTST9xE5Wk3jvqoy8iclxOJf14Cz+5946upS8iclxOJf20LX0lfRGRhBxL+r1b+q0q74iI9JJTST+1n77KOyIiveVU0u/qSe2nr5OzRESS5VTST7T0Y053rIfOWI/KOyIiSXIs6R+/9k78ssoq74iIHJdTST9e3on1eOL+uOq9IyJyXE4l/e6k3ju6gYqIyIlyLOkfb+nHb6Ci8o6IyHE5lfS7Emfk9iRa+qVK+iIiCTmV9JNb+u3xpF+kpC8iEpdTST/5dokdXdHz0nE5tYoiIsOSUxkxfvmFHidR3ilRS19EJCGnkn68pQ/Q0tENqKUvIpIspzJivKYPyUlfLX0RkbicSvq9Wvqd8fJOTq2iiMiw5FRGjNf0QS19EZF0cirpd8V6KLDoeata+iIiJ8ipjNgd80TLvrmjm6ICo6gwp1ZRRGRYciojdvccv5RyS0e3SjsiIilyJum7O11JLf2WzphKOyIiKXImK8ZvkVgS+uWrpS8icqKcSfrxnjvxa+20dHQnNgAiIhLJmawY76MfPwO3pbNbl2AQEUmRM0k/fjZuoqbfEdMlGEREUuRUVpx32nimjC8FQnlHB3JFRHrJKCua2U1m9ryZbTSzu8ys1MyeMLP14bHLzB7sY94Pmdmr4fGhkQ3/uNqKYh799Fu4asFUADq6e3QgV0QkRdFAE5jZNOBTwDx3bzOze4Br3P0tSdPcDzyUZt4JwM3AIsCBNWb2C3c/NFIrkKqo4Ph2TDdQERHpLdP6RxFQZmZFQDmwKz7CzKqAtwHpWvpXAI+7+8GQ6B8HrhxeyP0rjF+HAdR7R0Qkhbn7wBOZfRr4OtAGPObu1yaN+yBwlbu/L818fw2UuvvXwusvAW3u/q2U6W4AbgCYPHnywmXLlmW8As3NzVRWViZev3IoxjdWtQNwaUMRHz23JONljbTU2LJFtsYFim2oFNvgZWtcMLTYli5dusbdFw00XSblnVrgamAWcBi418yuc/efhEn+BLitr9nTDDthK+PutwK3AixatMiXLFkyUFgJK1asIHn68U2HYNVKAGY2TmPJknMzXtZIS40tW2RrXKDYhkqxDV62xgWjG1sm9Y/Lga3uvs/du4AHgEsAzKwOeAPwSB/z7gQak143kFQaGg1FSeUdHcgVEektk6TfBCw2s3IzM+Ay4MUw7v3Aw+7e3se8/wW8w8xqwx7DO8KwUZNc0y9Vl00RkV4GzIruvgq4D1gLPBfmuTWMvga4K3l6M1tkZreFeQ8Cfw88Ex5fDcNGTXLvnRK19EVEehmwpg/g7jcTdb1MHb4kzbDVwPVJr+8A7hh6iIPTq/eOWvoiIr3kXFZUTV9EpG85l/TV0hcR6VvOZcVCtfRFRPqUc0m/SC19EZE+5VxWVEtfRKRvOZf0e11wTUlfRKSXnEv6hYUq74iI9CXnsqK6bIqI9C3nkr66bIqI9C3nsmKhqaUvItKXnEv6BQVGvLGvG6OLiPSWk1kx3oOnRLdLFBHpJSeTfryur5q+iEhvOZkVCwuM4sICCgrS3bhLRCR/5WzS103RRUROlNH19E81RQVGQYGSvohIqpxM+oUFRrHq+SIiJ8jJzFhUYOqjLyKSRk4m/cJCUx99EZE0cjIzFhUUqI++iEgaOZn0CwvU0hcRSScnM2NRgamlLyKSRk723vnLJXOoLS8e6zBERLJOTib9qxdMG+sQRESyUk6Wd0REJD0lfRGRPKKkLyKSR5T0RUTyiJK+iEgeUdIXEckjSvoiInlESV9EJI+Yu491DL2Y2T5g+yBmmQjsH6VwhitbY8vWuECxDZViG7xsjQuGFtsMd5800ERZl/QHy8xWu/uisY4jnWyNLVvjAsU2VIpt8LI1Lhjd2FTeERHJI0r6IiJ5JBeS/q1jHUA/sjW2bI0LFNtQKbbBy9a4YBRjO+Vr+iIikrlcaOmLiEiGlPRFRPJIViV9M7vSzF42s01m9jdpxpeY2d1h/Cozm5k07m/D8JfN7IpMlznGsd1hZnvNbONQ4xqN2Mys0cyWm9mLZva8mX06i2IrNbOnzezZENtXsiW2pHGFZrbOzB7OlrjMbJuZPWdm681s9VDiGsXYaszsPjN7KfzmLs6G2MzszPB5xR9Hzewz2RBbGH5T+B/YaGZ3mVlpRsG4e1Y8gEJgMzAbKAaeBealTPNx4Afh+TXA3eH5vDB9CTArLKcwk2WOVWxh3KXAhcDGLPvcTgMuDNNUAa9ky+cGGFAZphkHrAIWZ0NsSfP9FfAz4OFsiQvYBkzMtv/RMO5HwPXheTFQky2xpSz/daIToMY8NmAasBUoC9PdA3w4k3iyqaX/BmCTu29x905gGXB1yjRXE/1AAO4DLjMzC8OXuXuHu28FNoXlZbLMsYoNd/8tcHAI8YxqbO6+293XhhiPAS8S/ciyITZ39+Yw/bjwGEpvhFH5Ts2sAXgXcNsQYhq1uEbIiMdmZuOJGj+3A7h7p7sfzobYUua9DNjs7oO5WsBox1YElJlZEVAO7MokmGxK+tOAHUmvd3JioklM4+7dwBGgrp95M1nmWMU2UkY1trCbeQFRizorYgvlk/XAXuBxd8+a2IB/Aj4H9AwhptGMy4HHzGyNmd2QRbHNBvYBPwwlsdvMrCJLYkt2DXDXEOIaldjc/TXgW0ATsBs44u6PZRJMNiV9SzMstQXX1zSDHT5YoxHbSBm12MysErgf+Iy7H82W2Nw95u4LgAai1uK52RCbmb0b2Ovua4YQz6jFFf6+yd0vBN4JfMLMLs2S2IqISpzfd/cLgBZgKMfeRvP/oBi4Crh3CHGNSmxmVku0FzALmApUmNl1mQSTTUl/J9CY9LqBE3dXEtOEXZpqovJIX/Nmssyxim2kjEpsZjaOKOH/1N0fyKbY4kIZYAVwZZbE9ibgKjPbRrQL/zYz+0kWxIW7x//uBX7O0Mo+o/U/ujNpb+0+oo1ANsQW905grbvvGUJcoxXb5cBWd9/n7l3AA8AlGUUz2IMSo/Ug2uJvIdpyxQ92nJMyzSfofbDjnvD8HHof7NhCdLBjwGWOVWxJ881keAdyR+NzM+BO4J+y8DudRDjQB5QBTwDvzobYUuZdwtAO5I7GZ1YBVIVpKoCVwJXZEFsY9wRwZnj+d8A/ZEtsYfwy4CNZ9n/wRuB5olq+ER0P+J8ZxTOcf+qRfgB/QNRTZDPwhTDsq8BV4Xkp0S7WJuBpYHbSvF8I870MvLO/ZWZRbHcR1eO6iLbof54NsQFvJtq13ACsD48/yJLY5gPrQmwbgS9n03eaNH4JQ0j6o/SZzSZKHM8SJYps+z9YAKwO3+mDQG0WxVYOHACqh/qZjWJsXwFeCv8HPwZKMolFl2EQEckj2VTTFxGRUaakLyKSR5T0RUTyiJK+iEgeUdIXEckjSvoiInlESV9EJI/8f6BNfdc/XXP0AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(regul_values, accuracy_val)\n",
    "plt.grid(True)\n",
    "plt.title('Test accuracy by regularization (logistic)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see if the same technique will improve the prediction of the 1-layer neural network:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 128\n",
    "\n",
    "graph = tf.Graph()\n",
    "with graph.as_default():\n",
    "\n",
    "    # Input data. For the training data, we use a placeholder that will be fed\n",
    "    # at run time with a training minibatch.\n",
    "    tf_train_dataset = tf.placeholder(tf.float32, shape=(batch_size, image_size * image_size))\n",
    "    tf_train_labels = tf.placeholder(tf.float32, shape=(batch_size, num_labels))\n",
    "    tf_valid_dataset = tf.constant(valid_dataset)\n",
    "    tf_test_dataset = tf.constant(test_dataset)\n",
    "    beta_regul = tf.placeholder(tf.float32)\n",
    "    \n",
    "    # Variables.\n",
    "    hidden_layer_size = 1024\n",
    "    hidden_weights = tf.Variable(tf.truncated_normal([image_size * image_size, hidden_layer_size]))\n",
    "    hidden_biases = tf.Variable(tf.zeros([hidden_layer_size]))\n",
    "    \n",
    "    hidden_logits = tf.nn.relu(tf.matmul(tf_train_dataset, hidden_weights) + hidden_biases)\n",
    "\n",
    "    # Variables.\n",
    "    weights = tf.Variable(tf.truncated_normal([hidden_layer_size, num_labels]))\n",
    "    biases = tf.Variable(tf.zeros([num_labels]))\n",
    "\n",
    "    # Training computation.\n",
    "    logits = tf.matmul(hidden_logits, weights) + biases\n",
    "    loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(labels=tf_train_labels, logits=logits))+ \\\n",
    "      beta_regul * (tf.nn.l2_loss(hidden_weights) + tf.nn.l2_loss(weights))\n",
    "\n",
    "    # Optimizer.\n",
    "    optimizer = tf.train.GradientDescentOptimizer(0.5).minimize(loss)\n",
    "\n",
    "    # Predictions for the training, validation, and test data.\n",
    "    train_prediction = tf.nn.softmax(logits)\n",
    "    hidden_valid_weights = tf.nn.relu(tf.matmul(tf_valid_dataset, hidden_weights) + hidden_biases)\n",
    "    valid_prediction = tf.nn.softmax(tf.matmul(hidden_valid_weights, weights) + biases)\n",
    "    hidden_test_weights = tf.nn.relu(tf.matmul(tf_test_dataset, hidden_weights) + hidden_biases)\n",
    "    test_prediction = tf.nn.softmax(tf.matmul(hidden_test_weights, weights) + biases)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialized\n",
      "Minibatch loss at step 0: 687.077759\n",
      "Minibatch accuracy: 13.3%\n",
      "Validation accuracy: 39.4%\n",
      "Minibatch loss at step 500: 198.096100\n",
      "Minibatch accuracy: 82.0%\n",
      "Validation accuracy: 77.9%\n",
      "Minibatch loss at step 1000: 114.316017\n",
      "Minibatch accuracy: 82.0%\n",
      "Validation accuracy: 81.3%\n",
      "Minibatch loss at step 1500: 68.082321\n",
      "Minibatch accuracy: 89.1%\n",
      "Validation accuracy: 83.0%\n",
      "Minibatch loss at step 2000: 41.085484\n",
      "Minibatch accuracy: 89.8%\n",
      "Validation accuracy: 84.6%\n",
      "Minibatch loss at step 2500: 25.023912\n",
      "Minibatch accuracy: 91.4%\n",
      "Validation accuracy: 85.6%\n",
      "Minibatch loss at step 3000: 15.451547\n",
      "Minibatch accuracy: 85.9%\n",
      "Validation accuracy: 86.4%\n",
      "Test accuracy: 93.2%\n"
     ]
    }
   ],
   "source": [
    "num_steps = 3001\n",
    "\n",
    "with tf.Session(graph=graph) as session:\n",
    "    tf.global_variables_initializer().run()\n",
    "    print(\"Initialized\")\n",
    "    for step in range(num_steps):\n",
    "            # Pick an offset within the training data, which has been randomized.\n",
    "            # Note: we could use better randomization across epochs.\n",
    "            offset = (step * batch_size) % (train_labels.shape[0] - batch_size)\n",
    "            # Generate a minibatch.\n",
    "            batch_data = train_dataset[offset:(offset + batch_size), :]\n",
    "            batch_labels = train_labels[offset:(offset + batch_size), :]\n",
    "            # Prepare a dictionary telling the session where to feed the minibatch.\n",
    "            # The key of the dictionary is the placeholder node of the graph to be fed,\n",
    "            # and the value is the numpy array to feed to it.\n",
    "            feed_dict = {tf_train_dataset : batch_data, tf_train_labels : batch_labels, beta_regul : 0.001 }\n",
    "            _, l, predictions = session.run([optimizer, loss, train_prediction], feed_dict=feed_dict)\n",
    "            if (step % 500 == 0):\n",
    "                print(\"Minibatch loss at step %d: %f\" % (step, l))\n",
    "                print(\"Minibatch accuracy: %.1f%%\" % accuracy(predictions, batch_labels))\n",
    "                print(\"Validation accuracy: %.1f%%\" % accuracy(valid_prediction.eval(), valid_labels))\n",
    "    print(\"Test accuracy: %.1f%%\" % accuracy(test_prediction.eval(), test_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialized for reg = 0.0001\n",
      "Initialized for reg = 0.00012589254117941674\n",
      "Initialized for reg = 0.00015848931924611142\n",
      "Initialized for reg = 0.0001995262314968881\n",
      "Initialized for reg = 0.0002511886431509582\n",
      "Initialized for reg = 0.00031622776601683826\n",
      "Initialized for reg = 0.00039810717055349773\n",
      "Initialized for reg = 0.000501187233627273\n",
      "Initialized for reg = 0.0006309573444801943\n",
      "Initialized for reg = 0.0007943282347242829\n",
      "Initialized for reg = 0.001000000000000002\n",
      "Initialized for reg = 0.00125892541179417\n",
      "Initialized for reg = 0.0015848931924611173\n",
      "Initialized for reg = 0.001995262314968885\n",
      "Initialized for reg = 0.0025118864315095872\n",
      "Initialized for reg = 0.003162277660168389\n",
      "Initialized for reg = 0.0039810717055349856\n",
      "Initialized for reg = 0.00501187233627274\n",
      "Initialized for reg = 0.006309573444801955\n",
      "Initialized for reg = 0.007943282347242847\n"
     ]
    }
   ],
   "source": [
    "regul_values = [pow(10, i) for i in np.arange(-4, -2, 0.1)]\n",
    "accuracy_val = []\n",
    "\n",
    "for beta in regul_values:\n",
    "    with tf.Session(graph=graph) as session:\n",
    "        tf.global_variables_initializer().run()\n",
    "        print(\"Initialized for reg = {0}\".format(beta))\n",
    "        for step in range(num_steps):\n",
    "                offset = (step * batch_size) % (train_labels.shape[0] - batch_size)\n",
    "                batch_data = train_dataset[offset:(offset + batch_size), :]\n",
    "                batch_labels = train_labels[offset:(offset + batch_size), :]\n",
    "                feed_dict = {tf_train_dataset : batch_data, tf_train_labels : batch_labels, beta_regul : beta}\n",
    "                _, l, predictions = session.run([optimizer, loss, train_prediction], feed_dict=feed_dict)\n",
    "        accuracy_val.append(accuracy(test_prediction.eval(), test_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.semilogx(regul_values, accuracy_val)\n",
    "plt.grid(True)\n",
    "plt.title('Test accuracy by regularization (logistic)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "na8xX2yHZzNF"
   },
   "source": [
    "---\n",
    "Problem 2\n",
    "---------\n",
    "Let's demonstrate an extreme case of overfitting. Restrict your training data to just a few batches. What happens?\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 128\n",
    "num_hidden_nodes = 1024\n",
    "\n",
    "graph = tf.Graph()\n",
    "with graph.as_default():\n",
    "\n",
    "    # Input data. For the training data, we use a placeholder that will be fed\n",
    "    # at run time with a training minibatch.\n",
    "    tf_train_dataset = tf.placeholder(tf.float32, shape=(batch_size, image_size * image_size))\n",
    "    tf_train_labels = tf.placeholder(tf.float32, shape=(batch_size, num_labels))\n",
    "    tf_valid_dataset = tf.constant(valid_dataset)\n",
    "    tf_test_dataset = tf.constant(test_dataset)\n",
    "    beta_regul = tf.placeholder(tf.float32)\n",
    "\n",
    "    # Variables.\n",
    "    weights1 = tf.Variable(\n",
    "    tf.truncated_normal([image_size * image_size, num_hidden_nodes]))\n",
    "    biases1 = tf.Variable(tf.zeros([num_hidden_nodes]))\n",
    "    weights2 = tf.Variable(tf.truncated_normal([num_hidden_nodes, num_labels]))\n",
    "    biases2 = tf.Variable(tf.zeros([num_labels]))\n",
    "\n",
    "    # Training computation.\n",
    "    lay1_train = tf.nn.relu(tf.matmul(tf_train_dataset, weights1) + biases1)\n",
    "    logits = tf.matmul(lay1_train, weights2) + biases2\n",
    "    loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(labels=tf_train_labels, logits=logits))\n",
    "\n",
    "    # Optimizer.\n",
    "    optimizer = tf.train.GradientDescentOptimizer(0.5).minimize(loss)\n",
    "\n",
    "    # Predictions for the training, validation, and test data.\n",
    "    train_prediction = tf.nn.softmax(logits)\n",
    "    lay1_valid = tf.nn.relu(tf.matmul(tf_valid_dataset, weights1) + biases1)\n",
    "    valid_prediction = tf.nn.softmax(tf.matmul(lay1_valid, weights2) + biases2)\n",
    "    lay1_test = tf.nn.relu(tf.matmul(tf_test_dataset, weights1) + biases1)\n",
    "    test_prediction = tf.nn.softmax(tf.matmul(lay1_test, weights2) + biases2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialized\n",
      "Minibatch loss at step 0: 297.189026\n",
      "Minibatch accuracy: 10.2%\n",
      "Validation accuracy: 34.0%\n",
      "Minibatch loss at step 2: 1732.683350\n",
      "Minibatch accuracy: 34.4%\n",
      "Validation accuracy: 41.1%\n",
      "Minibatch loss at step 4: 228.338791\n",
      "Minibatch accuracy: 60.2%\n",
      "Validation accuracy: 62.3%\n",
      "Minibatch loss at step 6: 90.182762\n",
      "Minibatch accuracy: 70.3%\n",
      "Validation accuracy: 64.5%\n",
      "Minibatch loss at step 8: 41.099766\n",
      "Minibatch accuracy: 82.8%\n",
      "Validation accuracy: 70.8%\n",
      "Minibatch loss at step 10: 39.506241\n",
      "Minibatch accuracy: 88.3%\n",
      "Validation accuracy: 72.8%\n",
      "Minibatch loss at step 12: 21.438553\n",
      "Minibatch accuracy: 93.0%\n",
      "Validation accuracy: 73.6%\n",
      "Minibatch loss at step 14: 5.870131\n",
      "Minibatch accuracy: 94.5%\n",
      "Validation accuracy: 73.3%\n",
      "Minibatch loss at step 16: 2.230348\n",
      "Minibatch accuracy: 98.4%\n",
      "Validation accuracy: 73.2%\n",
      "Minibatch loss at step 18: 6.779141\n",
      "Minibatch accuracy: 97.7%\n",
      "Validation accuracy: 73.7%\n",
      "Minibatch loss at step 20: 0.000000\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 73.7%\n",
      "Minibatch loss at step 22: 0.000009\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 73.8%\n",
      "Minibatch loss at step 24: 0.000000\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 73.8%\n",
      "Minibatch loss at step 26: 0.000000\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 73.8%\n",
      "Minibatch loss at step 28: 0.000006\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 73.8%\n",
      "Minibatch loss at step 30: 0.000000\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 73.8%\n",
      "Minibatch loss at step 32: 0.000000\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 73.8%\n",
      "Minibatch loss at step 34: 0.000004\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 73.8%\n",
      "Minibatch loss at step 36: 0.000000\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 73.8%\n",
      "Minibatch loss at step 38: 0.000000\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 73.8%\n",
      "Minibatch loss at step 40: 0.000003\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 73.8%\n",
      "Minibatch loss at step 42: 0.000000\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 73.8%\n",
      "Minibatch loss at step 44: 0.000000\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 73.8%\n",
      "Minibatch loss at step 46: 0.000003\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 73.8%\n",
      "Minibatch loss at step 48: 0.000000\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 73.8%\n",
      "Minibatch loss at step 50: 0.000000\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 73.8%\n",
      "Minibatch loss at step 52: 0.000002\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 73.8%\n",
      "Minibatch loss at step 54: 0.000000\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 73.8%\n",
      "Minibatch loss at step 56: 0.000000\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 73.8%\n",
      "Minibatch loss at step 58: 0.000002\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 73.8%\n",
      "Minibatch loss at step 60: 0.000000\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 73.8%\n",
      "Minibatch loss at step 62: 0.000000\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 73.8%\n",
      "Minibatch loss at step 64: 0.000002\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 73.8%\n",
      "Minibatch loss at step 66: 0.000000\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 73.8%\n",
      "Minibatch loss at step 68: 0.000000\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 73.8%\n",
      "Minibatch loss at step 70: 0.000002\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 73.8%\n",
      "Minibatch loss at step 72: 0.000000\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 73.8%\n",
      "Minibatch loss at step 74: 0.000000\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 73.8%\n",
      "Minibatch loss at step 76: 0.000001\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 73.8%\n",
      "Minibatch loss at step 78: 0.000000\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 73.8%\n",
      "Minibatch loss at step 80: 0.000000\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 73.8%\n",
      "Minibatch loss at step 82: 0.000001\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 73.8%\n",
      "Minibatch loss at step 84: 0.000000\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 73.8%\n",
      "Minibatch loss at step 86: 0.000000\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 73.8%\n",
      "Minibatch loss at step 88: 0.000001\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 73.8%\n",
      "Minibatch loss at step 90: 0.000000\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 73.8%\n",
      "Minibatch loss at step 92: 0.000000\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 73.8%\n",
      "Minibatch loss at step 94: 0.000001\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 73.8%\n",
      "Minibatch loss at step 96: 0.000000\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 73.8%\n",
      "Minibatch loss at step 98: 0.000000\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 73.8%\n",
      "Minibatch loss at step 100: 0.000001\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 73.8%\n",
      "Test accuracy: 81.7%\n"
     ]
    }
   ],
   "source": [
    "num_steps = 101\n",
    "num_batches = 3\n",
    "\n",
    "with tf.Session(graph=graph) as session:\n",
    "    tf.initialize_all_variables().run()\n",
    "    print(\"Initialized\")\n",
    "    for step in range(num_steps):\n",
    "        # Pick an offset within the training data, which has been randomized.\n",
    "        # Note: we could use better randomization across epochs.\n",
    "        #offset = (step * batch_size) % (train_labels.shape[0] - batch_size)\n",
    "        offset = ((step % num_batches) * batch_size) % (train_labels.shape[0] - batch_size)\n",
    "        # Generate a minibatch.\n",
    "        batch_data = train_dataset[offset:(offset + batch_size), :]\n",
    "        batch_labels = train_labels[offset:(offset + batch_size), :]\n",
    "        # Prepare a dictionary telling the session where to feed the minibatch.\n",
    "        # The key of the dictionary is the placeholder node of the graph to be fed,\n",
    "        # and the value is the numpy array to feed to it.\n",
    "        feed_dict = {tf_train_dataset : batch_data, tf_train_labels : batch_labels}\n",
    "        _, l, predictions = session.run([optimizer, loss, train_prediction], feed_dict=feed_dict)\n",
    "        if (step % 2 == 0):\n",
    "            print(\"Minibatch loss at step %d: %f\" % (step, l))\n",
    "            print(\"Minibatch accuracy: %.1f%%\" % accuracy(predictions, batch_labels))\n",
    "            print(\"Validation accuracy: %.1f%%\" % accuracy(valid_prediction.eval(), valid_labels))\n",
    "    print(\"Test accuracy: %.1f%%\" % accuracy(test_prediction.eval(), test_labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ww3SCBUdlkRc"
   },
   "source": [
    "---\n",
    "Problem 3\n",
    "---------\n",
    "Introduce Dropout on the hidden layer of the neural network. Remember: Dropout should only be introduced during training, not evaluation, otherwise your evaluation results would be stochastic as well. TensorFlow provides `nn.dropout()` for that, but you have to make sure it's only inserted during training.\n",
    "\n",
    "What happens to our extreme overfitting case?\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 128\n",
    "\n",
    "graph = tf.Graph()\n",
    "with graph.as_default():\n",
    "\n",
    "    # Input data. For the training data, we use a placeholder that will be fed\n",
    "    # at run time with a training minibatch.\n",
    "    tf_train_dataset = tf.placeholder(tf.float32, shape=(batch_size, image_size * image_size))\n",
    "    tf_train_labels = tf.placeholder(tf.float32, shape=(batch_size, num_labels))\n",
    "    tf_valid_dataset = tf.constant(valid_dataset)\n",
    "    tf_test_dataset = tf.constant(test_dataset)\n",
    "    \n",
    "    # Variables.\n",
    "    hidden_layer_size = 1024\n",
    "    hidden_weights = tf.Variable(tf.truncated_normal([image_size * image_size, hidden_layer_size]))\n",
    "    hidden_biases = tf.Variable(tf.zeros([hidden_layer_size]))\n",
    "    \n",
    "    hidden_logits = tf.nn.relu(tf.matmul(tf_train_dataset, hidden_weights) + hidden_biases)\n",
    "    \n",
    "    drop1 = tf.nn.dropout(hidden_logits, 0.5)\n",
    "\n",
    "    # Variables.\n",
    "    weights = tf.Variable(tf.truncated_normal([hidden_layer_size, num_labels]))\n",
    "    biases = tf.Variable(tf.zeros([num_labels]))\n",
    "\n",
    "    # Training computation.\n",
    "    logits = tf.matmul(drop1, weights) + biases\n",
    "    loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(labels=tf_train_labels, logits=logits))\n",
    "\n",
    "    # Optimizer.\n",
    "    optimizer = tf.train.GradientDescentOptimizer(0.5).minimize(loss)\n",
    "\n",
    "    # Predictions for the training, validation, and test data.\n",
    "    train_prediction = tf.nn.softmax(logits)\n",
    "    hidden_valid_weights = tf.nn.relu(tf.matmul(tf_valid_dataset, hidden_weights) + hidden_biases)\n",
    "    valid_prediction = tf.nn.softmax(tf.matmul(hidden_valid_weights, weights) + biases)\n",
    "    hidden_test_weights = tf.nn.relu(tf.matmul(tf_test_dataset, hidden_weights) + hidden_biases)\n",
    "    test_prediction = tf.nn.softmax(tf.matmul(hidden_test_weights, weights) + biases)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialized\n",
      "Minibatch loss at step 0: 559.147217\n",
      "Minibatch accuracy: 7.8%\n",
      "Validation accuracy: 22.1%\n",
      "Minibatch loss at step 500: 42.017036\n",
      "Minibatch accuracy: 77.3%\n",
      "Validation accuracy: 80.2%\n",
      "Minibatch loss at step 1000: 18.145817\n",
      "Minibatch accuracy: 68.8%\n",
      "Validation accuracy: 80.1%\n",
      "Minibatch loss at step 1500: 14.035315\n",
      "Minibatch accuracy: 78.1%\n",
      "Validation accuracy: 79.4%\n",
      "Minibatch loss at step 2000: 5.352002\n",
      "Minibatch accuracy: 82.8%\n",
      "Validation accuracy: 79.0%\n",
      "Minibatch loss at step 2500: 3.674605\n",
      "Minibatch accuracy: 75.8%\n",
      "Validation accuracy: 79.5%\n",
      "Minibatch loss at step 3000: 3.032905\n",
      "Minibatch accuracy: 70.3%\n",
      "Validation accuracy: 79.4%\n",
      "Minibatch loss at step 3500: 5.646460\n",
      "Minibatch accuracy: 77.3%\n",
      "Validation accuracy: 78.5%\n",
      "Minibatch loss at step 4000: 8.307532\n",
      "Minibatch accuracy: 73.4%\n",
      "Validation accuracy: 80.1%\n",
      "Minibatch loss at step 4500: 8.705734\n",
      "Minibatch accuracy: 75.8%\n",
      "Validation accuracy: 79.8%\n",
      "Minibatch loss at step 5000: 5.267724\n",
      "Minibatch accuracy: 82.0%\n",
      "Validation accuracy: 80.0%\n",
      "Minibatch loss at step 5500: 5.570374\n",
      "Minibatch accuracy: 72.7%\n",
      "Validation accuracy: 80.5%\n",
      "Minibatch loss at step 6000: 3.595860\n",
      "Minibatch accuracy: 70.3%\n",
      "Validation accuracy: 80.0%\n",
      "Minibatch loss at step 6500: 3.983048\n",
      "Minibatch accuracy: 73.4%\n",
      "Validation accuracy: 80.1%\n",
      "Minibatch loss at step 7000: 4.564117\n",
      "Minibatch accuracy: 77.3%\n",
      "Validation accuracy: 81.1%\n",
      "Minibatch loss at step 7500: 3.504247\n",
      "Minibatch accuracy: 71.1%\n",
      "Validation accuracy: 81.2%\n",
      "Minibatch loss at step 8000: 4.795476\n",
      "Minibatch accuracy: 65.6%\n",
      "Validation accuracy: 81.6%\n",
      "Minibatch loss at step 8500: 1.463487\n",
      "Minibatch accuracy: 78.1%\n",
      "Validation accuracy: 81.8%\n",
      "Minibatch loss at step 9000: 3.383248\n",
      "Minibatch accuracy: 80.5%\n",
      "Validation accuracy: 81.6%\n",
      "Test accuracy: 88.5%\n"
     ]
    }
   ],
   "source": [
    "num_steps = 9001\n",
    "\n",
    "with tf.Session(graph=graph) as session:\n",
    "    tf.initialize_all_variables().run()\n",
    "    print(\"Initialized\")\n",
    "    for step in range(num_steps):\n",
    "        # Pick an offset within the training data, which has been randomized.\n",
    "        # Note: we could use better randomization across epochs.\n",
    "        offset = (step * batch_size) % (train_labels.shape[0] - batch_size)\n",
    "        # Generate a minibatch.\n",
    "        batch_data = train_dataset[offset:(offset + batch_size), :]\n",
    "        batch_labels = train_labels[offset:(offset + batch_size), :]\n",
    "        # Prepare a dictionary telling the session where to feed the minibatch.\n",
    "        # The key of the dictionary is the placeholder node of the graph to be fed,\n",
    "        # and the value is the numpy array to feed to it.\n",
    "        feed_dict = {tf_train_dataset : batch_data, tf_train_labels : batch_labels}\n",
    "        _, l, predictions = session.run(\n",
    "          [optimizer, loss, train_prediction], feed_dict=feed_dict)\n",
    "        if (step % 500 == 0):\n",
    "            print(\"Minibatch loss at step %d: %f\" % (step, l))\n",
    "            print(\"Minibatch accuracy: %.1f%%\" % accuracy(predictions, batch_labels))\n",
    "            print(\"Validation accuracy: %.1f%%\" % accuracy(valid_prediction.eval(), valid_labels))\n",
    "    print(\"Test accuracy: %.1f%%\" % accuracy(test_prediction.eval(), test_labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first conclusion is that 100% of accuracy on the minibatches is more difficult achieved or to keep. As a result, the test accuracy is improved by 6%, the final net is more capable of generalization."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "-b1hTz3VWZjw"
   },
   "source": [
    "---\n",
    "Problem 4\n",
    "---------\n",
    "\n",
    "Try to get the best performance you can using a multi-layer model! The best reported test accuracy using a deep network is [97.1%](http://yaroslavvb.blogspot.com/2011/09/notmnist-dataset.html?showComment=1391023266211#c8758720086795711595).\n",
    "\n",
    "One avenue you can explore is to add multiple layers.\n",
    "\n",
    "Another one is to use learning rate decay:\n",
    "\n",
    "    global_step = tf.Variable(0)  # count the number of steps taken.\n",
    "    learning_rate = tf.train.exponential_decay(0.5, global_step, ...)\n",
    "    optimizer = tf.train.GradientDescentOptimizer(learning_rate).minimize(loss, global_step=global_step)\n",
    " \n",
    " ---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's do a first try with 2 layers. Note how the parameters are initialized, compared to the previous cases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 128\n",
    "num_hidden_nodes1 = 1024\n",
    "num_hidden_nodes2 = 100\n",
    "beta_regul = 1e-3\n",
    "\n",
    "graph = tf.Graph()\n",
    "with graph.as_default():\n",
    "\n",
    "    # Input data. For the training data, we use a placeholder that will be fed\n",
    "    # at run time with a training minibatch.\n",
    "    tf_train_dataset = tf.placeholder(tf.float32, shape=(batch_size, image_size * image_size))\n",
    "    tf_train_labels = tf.placeholder(tf.float32, shape=(batch_size, num_labels))\n",
    "    tf_valid_dataset = tf.constant(valid_dataset)\n",
    "    tf_test_dataset = tf.constant(test_dataset)\n",
    "    global_step = tf.Variable(0)\n",
    "    \n",
    "    # Variables.\n",
    "    weights1 = tf.Variable(tf.truncated_normal([image_size * image_size, num_hidden_nodes1],\n",
    "        stddev=np.sqrt(2.0 / (image_size * image_size))))\n",
    "    biases1 = tf.Variable(tf.zeros([num_hidden_nodes1]))\n",
    "    \n",
    "    weights2 = tf.Variable(tf.truncated_normal([num_hidden_nodes1, num_hidden_nodes2],\n",
    "        stddev=np.sqrt(2.0 / num_hidden_nodes1 )))\n",
    "    biases2 = tf.Variable(tf.zeros([num_hidden_nodes2]))\n",
    "    \n",
    "    weights3 = tf.Variable(tf.truncated_normal([num_hidden_nodes2, num_labels],\n",
    "        stddev=np.sqrt(2.0 / num_hidden_nodes2 )))\n",
    "    biases3 = tf.Variable(tf.zeros([num_labels]))\n",
    "    \n",
    "    train_lay1 = tf.nn.relu(tf.matmul(tf_train_dataset, weights1) + biases1)\n",
    "    train_lay2 = tf.nn.relu(tf.matmul(train_lay1, weights2) + biases2)\n",
    "    logits = tf.matmul(train_lay2, weights3) + biases3\n",
    "    \n",
    "    \n",
    "    loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(labels=tf_train_labels, logits=logits)) + \\\n",
    "      beta_regul * (tf.nn.l2_loss(weights1) + tf.nn.l2_loss(weights2) + tf.nn.l2_loss(weights3))\n",
    "    \n",
    "    # Optimizer.\n",
    "    learning_rate = tf.train.exponential_decay(0.5, global_step, 1000, 0.65, staircase=True)\n",
    "    optimizer = tf.train.GradientDescentOptimizer(learning_rate).minimize(loss, global_step=global_step)\n",
    "\n",
    "    # Predictions for the training, validation, and test data.\n",
    "    train_prediction = tf.nn.softmax(logits)\n",
    "    lay1_valid = tf.nn.relu(tf.matmul(tf_valid_dataset, weights1) + biases1)\n",
    "    lay2_valid = tf.nn.relu(tf.matmul(lay1_valid, weights2) + biases2)\n",
    "    valid_prediction = tf.nn.softmax(tf.matmul(lay2_valid, weights3) + biases3)\n",
    "    lay1_test = tf.nn.relu(tf.matmul(tf_test_dataset, weights1) + biases1)\n",
    "    lay2_test = tf.nn.relu(tf.matmul(lay1_test, weights2) + biases2)\n",
    "    test_prediction = tf.nn.softmax(tf.matmul(lay2_test, weights3) + biases3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialized\n",
      "Minibatch loss at step 0: 3.144927\n",
      "Minibatch accuracy: 15.6%\n",
      "Validation accuracy: 43.3%\n",
      "Minibatch loss at step 500: 0.920453\n",
      "Minibatch accuracy: 89.1%\n",
      "Validation accuracy: 85.5%\n",
      "Minibatch loss at step 1000: 0.846442\n",
      "Minibatch accuracy: 86.7%\n",
      "Validation accuracy: 86.5%\n",
      "Minibatch loss at step 1500: 0.573248\n",
      "Minibatch accuracy: 93.0%\n",
      "Validation accuracy: 87.6%\n",
      "Minibatch loss at step 2000: 0.541998\n",
      "Minibatch accuracy: 93.0%\n",
      "Validation accuracy: 87.9%\n",
      "Minibatch loss at step 2500: 0.472457\n",
      "Minibatch accuracy: 91.4%\n",
      "Validation accuracy: 88.2%\n",
      "Minibatch loss at step 3000: 0.558311\n",
      "Minibatch accuracy: 87.5%\n",
      "Validation accuracy: 88.7%\n",
      "Minibatch loss at step 3500: 0.544575\n",
      "Minibatch accuracy: 88.3%\n",
      "Validation accuracy: 89.0%\n",
      "Minibatch loss at step 4000: 0.480506\n",
      "Minibatch accuracy: 91.4%\n",
      "Validation accuracy: 88.9%\n",
      "Minibatch loss at step 4500: 0.444503\n",
      "Minibatch accuracy: 90.6%\n",
      "Validation accuracy: 89.1%\n",
      "Minibatch loss at step 5000: 0.502636\n",
      "Minibatch accuracy: 90.6%\n",
      "Validation accuracy: 89.4%\n",
      "Minibatch loss at step 5500: 0.501378\n",
      "Minibatch accuracy: 89.8%\n",
      "Validation accuracy: 89.5%\n",
      "Minibatch loss at step 6000: 0.491939\n",
      "Minibatch accuracy: 89.8%\n",
      "Validation accuracy: 89.6%\n",
      "Minibatch loss at step 6500: 0.414542\n",
      "Minibatch accuracy: 93.8%\n",
      "Validation accuracy: 89.7%\n",
      "Minibatch loss at step 7000: 0.492530\n",
      "Minibatch accuracy: 89.1%\n",
      "Validation accuracy: 89.8%\n",
      "Minibatch loss at step 7500: 0.414472\n",
      "Minibatch accuracy: 91.4%\n",
      "Validation accuracy: 89.9%\n",
      "Minibatch loss at step 8000: 0.609058\n",
      "Minibatch accuracy: 84.4%\n",
      "Validation accuracy: 89.9%\n",
      "Minibatch loss at step 8500: 0.434411\n",
      "Minibatch accuracy: 92.2%\n",
      "Validation accuracy: 90.0%\n",
      "Minibatch loss at step 9000: 0.492084\n",
      "Minibatch accuracy: 89.8%\n",
      "Validation accuracy: 90.0%\n",
      "Test accuracy: 95.6%\n"
     ]
    }
   ],
   "source": [
    "num_steps = 9001\n",
    "\n",
    "with tf.Session(graph=graph) as session:\n",
    "    tf.initialize_all_variables().run()\n",
    "    print(\"Initialized\")\n",
    "    for step in range(num_steps):\n",
    "        # Pick an offset within the training data, which has been randomized.\n",
    "        # Note: we could use better randomization across epochs.\n",
    "        offset = (step * batch_size) % (train_labels.shape[0] - batch_size)\n",
    "        # Generate a minibatch.\n",
    "        batch_data = train_dataset[offset:(offset + batch_size), :]\n",
    "        batch_labels = train_labels[offset:(offset + batch_size), :]\n",
    "        # Prepare a dictionary telling the session where to feed the minibatch.\n",
    "        # The key of the dictionary is the placeholder node of the graph to be fed,\n",
    "        # and the value is the numpy array to feed to it.\n",
    "        feed_dict = {tf_train_dataset : batch_data, tf_train_labels : batch_labels}\n",
    "        _, l, predictions = session.run(\n",
    "          [optimizer, loss, train_prediction], feed_dict=feed_dict)\n",
    "        if (step % 500 == 0):\n",
    "            print(\"Minibatch loss at step %d: %f\" % (step, l))\n",
    "            print(\"Minibatch accuracy: %.1f%%\" % accuracy(predictions, batch_labels))\n",
    "            print(\"Validation accuracy: %.1f%%\" % accuracy(valid_prediction.eval(), valid_labels))\n",
    "    print(\"Test accuracy: %.1f%%\" % accuracy(test_prediction.eval(), test_labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is getting really good. Let's try one layer deeper with dropouts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 128\n",
    "num_hidden_nodes1 = 1024\n",
    "num_hidden_nodes2 = 256\n",
    "num_hidden_nodes3 = 128\n",
    "keep_prob = 0.5\n",
    "\n",
    "graph = tf.Graph()\n",
    "with graph.as_default():\n",
    "\n",
    "    # Input data. For the training data, we use a placeholder that will be fed\n",
    "    # at run time with a training minibatch.\n",
    "    tf_train_dataset = tf.placeholder(tf.float32,shape=(batch_size, image_size * image_size))\n",
    "    tf_train_labels = tf.placeholder(tf.float32, shape=(batch_size, num_labels))\n",
    "    tf_valid_dataset = tf.constant(valid_dataset)\n",
    "    tf_test_dataset = tf.constant(test_dataset)\n",
    "    global_step = tf.Variable(0)\n",
    "\n",
    "    # Variables.\n",
    "    weights1 = tf.Variable(tf.truncated_normal([image_size * image_size, num_hidden_nodes1],stddev=np.sqrt(2.0 / (image_size * image_size))))\n",
    "    biases1 = tf.Variable(tf.zeros([num_hidden_nodes1]))\n",
    "    weights2 = tf.Variable(tf.truncated_normal([num_hidden_nodes1, num_hidden_nodes2], stddev=np.sqrt(2.0 / num_hidden_nodes1)))\n",
    "    biases2 = tf.Variable(tf.zeros([num_hidden_nodes2]))\n",
    "    weights3 = tf.Variable(tf.truncated_normal([num_hidden_nodes2, num_hidden_nodes3], stddev=np.sqrt(2.0 / num_hidden_nodes2)))\n",
    "    biases3 = tf.Variable(tf.zeros([num_hidden_nodes3]))\n",
    "    weights4 = tf.Variable(tf.truncated_normal([num_hidden_nodes3, num_labels], stddev=np.sqrt(2.0 / num_hidden_nodes3)))\n",
    "    biases4 = tf.Variable(tf.zeros([num_labels]))\n",
    "\n",
    "    # Training computation.\n",
    "    lay1_train = tf.nn.relu(tf.matmul(tf_train_dataset, weights1) + biases1)\n",
    "    lay2_train = tf.nn.relu(tf.matmul(lay1_train, weights2) + biases2)\n",
    "    lay3_train = tf.nn.relu(tf.matmul(lay2_train, weights3) + biases3)\n",
    "    logits = tf.matmul(lay3_train, weights4) + biases4\n",
    "    loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(labels=tf_train_labels, logits=logits))\n",
    "\n",
    "    # Optimizer.\n",
    "    learning_rate = tf.train.exponential_decay(0.5, global_step, 4000, 0.65, staircase=True)\n",
    "    optimizer = tf.train.GradientDescentOptimizer(learning_rate).minimize(loss, global_step=global_step)\n",
    "\n",
    "    # Predictions for the training, validation, and test data.\n",
    "    train_prediction = tf.nn.softmax(logits)\n",
    "    lay1_valid = tf.nn.relu(tf.matmul(tf_valid_dataset, weights1) + biases1)\n",
    "    lay2_valid = tf.nn.relu(tf.matmul(lay1_valid, weights2) + biases2)\n",
    "    lay3_valid = tf.nn.relu(tf.matmul(lay2_valid, weights3) + biases3)\n",
    "    valid_prediction = tf.nn.softmax(tf.matmul(lay3_valid, weights4) + biases4)\n",
    "    lay1_test = tf.nn.relu(tf.matmul(tf_test_dataset, weights1) + biases1)\n",
    "    lay2_test = tf.nn.relu(tf.matmul(lay1_test, weights2) + biases2)\n",
    "    lay3_test = tf.nn.relu(tf.matmul(lay2_test, weights3) + biases3)\n",
    "    test_prediction = tf.nn.softmax(tf.matmul(lay3_test, weights4) + biases4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialized\n",
      "Minibatch loss at step 0: 2.397277\n",
      "Minibatch accuracy: 11.7%\n",
      "Validation accuracy: 31.8%\n",
      "Minibatch loss at step 500: 0.359792\n",
      "Minibatch accuracy: 89.1%\n",
      "Validation accuracy: 85.5%\n",
      "Minibatch loss at step 1000: 0.454379\n",
      "Minibatch accuracy: 86.7%\n",
      "Validation accuracy: 86.7%\n",
      "Minibatch loss at step 1500: 0.232629\n",
      "Minibatch accuracy: 93.8%\n",
      "Validation accuracy: 87.6%\n",
      "Minibatch loss at step 2000: 0.248694\n",
      "Minibatch accuracy: 93.8%\n",
      "Validation accuracy: 88.4%\n",
      "Minibatch loss at step 2500: 0.228819\n",
      "Minibatch accuracy: 93.0%\n",
      "Validation accuracy: 88.8%\n",
      "Minibatch loss at step 3000: 0.304848\n",
      "Minibatch accuracy: 88.3%\n",
      "Validation accuracy: 88.9%\n",
      "Minibatch loss at step 3500: 0.335620\n",
      "Minibatch accuracy: 89.8%\n",
      "Validation accuracy: 89.1%\n",
      "Minibatch loss at step 4000: 0.285118\n",
      "Minibatch accuracy: 90.6%\n",
      "Validation accuracy: 89.2%\n",
      "Minibatch loss at step 4500: 0.220518\n",
      "Minibatch accuracy: 93.0%\n",
      "Validation accuracy: 89.5%\n",
      "Minibatch loss at step 5000: 0.286283\n",
      "Minibatch accuracy: 93.0%\n",
      "Validation accuracy: 90.0%\n",
      "Minibatch loss at step 5500: 0.239030\n",
      "Minibatch accuracy: 89.8%\n",
      "Validation accuracy: 89.5%\n",
      "Minibatch loss at step 6000: 0.227975\n",
      "Minibatch accuracy: 89.8%\n",
      "Validation accuracy: 89.8%\n",
      "Minibatch loss at step 6500: 0.245753\n",
      "Minibatch accuracy: 94.5%\n",
      "Validation accuracy: 89.8%\n",
      "Minibatch loss at step 7000: 0.283040\n",
      "Minibatch accuracy: 90.6%\n",
      "Validation accuracy: 89.9%\n",
      "Minibatch loss at step 7500: 0.263539\n",
      "Minibatch accuracy: 89.8%\n",
      "Validation accuracy: 89.8%\n",
      "Minibatch loss at step 8000: 0.285332\n",
      "Minibatch accuracy: 90.6%\n",
      "Validation accuracy: 89.9%\n",
      "Minibatch loss at step 8500: 0.144443\n",
      "Minibatch accuracy: 95.3%\n",
      "Validation accuracy: 90.5%\n",
      "Minibatch loss at step 9000: 0.212954\n",
      "Minibatch accuracy: 96.1%\n",
      "Validation accuracy: 90.4%\n",
      "Minibatch loss at step 9500: 0.168671\n",
      "Minibatch accuracy: 94.5%\n",
      "Validation accuracy: 90.4%\n",
      "Minibatch loss at step 10000: 0.151567\n",
      "Minibatch accuracy: 95.3%\n",
      "Validation accuracy: 90.7%\n",
      "Minibatch loss at step 10500: 0.176189\n",
      "Minibatch accuracy: 94.5%\n",
      "Validation accuracy: 90.4%\n",
      "Minibatch loss at step 11000: 0.073146\n",
      "Minibatch accuracy: 98.4%\n",
      "Validation accuracy: 90.5%\n",
      "Minibatch loss at step 11500: 0.089539\n",
      "Minibatch accuracy: 97.7%\n",
      "Validation accuracy: 90.6%\n",
      "Minibatch loss at step 12000: 0.220131\n",
      "Minibatch accuracy: 92.2%\n",
      "Validation accuracy: 90.6%\n",
      "Minibatch loss at step 12500: 0.080949\n",
      "Minibatch accuracy: 97.7%\n",
      "Validation accuracy: 90.6%\n",
      "Minibatch loss at step 13000: 0.138035\n",
      "Minibatch accuracy: 96.1%\n",
      "Validation accuracy: 90.7%\n",
      "Minibatch loss at step 13500: 0.081558\n",
      "Minibatch accuracy: 96.9%\n",
      "Validation accuracy: 90.9%\n",
      "Minibatch loss at step 14000: 0.117881\n",
      "Minibatch accuracy: 94.5%\n",
      "Validation accuracy: 90.8%\n",
      "Minibatch loss at step 14500: 0.158046\n",
      "Minibatch accuracy: 96.1%\n",
      "Validation accuracy: 90.6%\n",
      "Minibatch loss at step 15000: 0.063500\n",
      "Minibatch accuracy: 99.2%\n",
      "Validation accuracy: 90.9%\n",
      "Minibatch loss at step 15500: 0.096916\n",
      "Minibatch accuracy: 97.7%\n",
      "Validation accuracy: 91.0%\n",
      "Minibatch loss at step 16000: 0.054403\n",
      "Minibatch accuracy: 97.7%\n",
      "Validation accuracy: 90.6%\n",
      "Minibatch loss at step 16500: 0.057806\n",
      "Minibatch accuracy: 97.7%\n",
      "Validation accuracy: 90.9%\n",
      "Minibatch loss at step 17000: 0.061976\n",
      "Minibatch accuracy: 97.7%\n",
      "Validation accuracy: 91.0%\n",
      "Minibatch loss at step 17500: 0.018385\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 91.0%\n",
      "Minibatch loss at step 18000: 0.038444\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 91.0%\n",
      "Test accuracy: 96.3%\n"
     ]
    }
   ],
   "source": [
    "num_steps = 18001\n",
    "\n",
    "with tf.Session(graph=graph) as session:\n",
    "    tf.initialize_all_variables().run()\n",
    "    print(\"Initialized\")\n",
    "    for step in range(num_steps):\n",
    "        # Pick an offset within the training data, which has been randomized.\n",
    "        # Note: we could use better randomization across epochs.\n",
    "        offset = (step * batch_size) % (train_labels.shape[0] - batch_size)\n",
    "        # Generate a minibatch.\n",
    "        batch_data = train_dataset[offset:(offset + batch_size), :]\n",
    "        batch_labels = train_labels[offset:(offset + batch_size), :]\n",
    "        # Prepare a dictionary telling the session where to feed the minibatch.\n",
    "        # The key of the dictionary is the placeholder node of the graph to be fed,\n",
    "        # and the value is the numpy array to feed to it.\n",
    "        feed_dict = {tf_train_dataset : batch_data, tf_train_labels : batch_labels}\n",
    "        _, l, predictions = session.run(\n",
    "          [optimizer, loss, train_prediction], feed_dict=feed_dict)\n",
    "        if (step % 500 == 0):\n",
    "            print(\"Minibatch loss at step %d: %f\" % (step, l))\n",
    "            print(\"Minibatch accuracy: %.1f%%\" % accuracy(predictions, batch_labels))\n",
    "            print(\"Validation accuracy: %.1f%%\" % accuracy(valid_prediction.eval(), valid_labels))\n",
    "    print(\"Test accuracy: %.1f%%\" % accuracy(test_prediction.eval(), test_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "default_view": {},
   "name": "3_regularization.ipynb",
   "provenance": [],
   "version": "0.3.2",
   "views": {}
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
