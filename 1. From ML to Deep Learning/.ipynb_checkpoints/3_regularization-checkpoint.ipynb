{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "kR-4eNdK6lYS"
   },
   "source": [
    "Deep Learning\n",
    "=============\n",
    "\n",
    "Assignment 3\n",
    "------------\n",
    "\n",
    "Previously in `2_fullyconnected.ipynb`, you trained a logistic regression and a neural network model.\n",
    "\n",
    "The goal of this assignment is to explore regularization techniques."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "cellView": "both",
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "JLpLa8Jt7Vu4"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "# These are all the modules we'll be using later. Make sure you can import them\n",
    "# before proceeding further.\n",
    "from __future__ import print_function\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from six.moves import cPickle as pickle\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "1HrCK6e17WzV"
   },
   "source": [
    "First reload the data we generated in `1_notmnist.ipynb`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "cellView": "both",
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "output_extras": [
      {
       "item_id": 1
      }
     ]
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 11777,
     "status": "ok",
     "timestamp": 1449849322348,
     "user": {
      "color": "",
      "displayName": "",
      "isAnonymous": false,
      "isMe": true,
      "permissionId": "",
      "photoUrl": "",
      "sessionId": "0",
      "userId": ""
     },
     "user_tz": 480
    },
    "id": "y3-cj1bpmuxc",
    "outputId": "e03576f1-ebbe-4838-c388-f1777bcc9873"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set (200000, 28, 28) (200000,)\n",
      "Validation set (10000, 28, 28) (10000,)\n",
      "Test set (10000, 28, 28) (10000,)\n"
     ]
    }
   ],
   "source": [
    "pickle_file = 'all_data/notMNIST.pickle'\n",
    "\n",
    "with open(pickle_file, 'rb') as f:\n",
    "    save = pickle.load(f)\n",
    "    train_dataset = save['train_dataset']\n",
    "    train_labels = save['train_labels']\n",
    "    valid_dataset = save['valid_dataset']\n",
    "    valid_labels = save['valid_labels']\n",
    "    test_dataset = save['test_dataset']\n",
    "    test_labels = save['test_labels']\n",
    "    del save  # hint to help gc free up memory\n",
    "    print('Training set', train_dataset.shape, train_labels.shape)\n",
    "    print('Validation set', valid_dataset.shape, valid_labels.shape)\n",
    "    print('Test set', test_dataset.shape, test_labels.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "L7aHrm6nGDMB"
   },
   "source": [
    "Reformat into a shape that's more adapted to the models we're going to train:\n",
    "- data as a flat matrix,\n",
    "- labels as float 1-hot encodings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "cellView": "both",
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "output_extras": [
      {
       "item_id": 1
      }
     ]
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 11728,
     "status": "ok",
     "timestamp": 1449849322356,
     "user": {
      "color": "",
      "displayName": "",
      "isAnonymous": false,
      "isMe": true,
      "permissionId": "",
      "photoUrl": "",
      "sessionId": "0",
      "userId": ""
     },
     "user_tz": 480
    },
    "id": "IRSyYiIIGIzS",
    "outputId": "3f8996ee-3574-4f44-c953-5c8a04636582"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set (200000, 784) (200000, 10)\n",
      "Validation set (10000, 784) (10000, 10)\n",
      "Test set (10000, 784) (10000, 10)\n"
     ]
    }
   ],
   "source": [
    "image_size = 28\n",
    "num_labels = 10\n",
    "\n",
    "def reformat(dataset, labels):\n",
    "    dataset = dataset.reshape((-1, image_size * image_size)).astype(np.float32)\n",
    "    # Map 1 to [0.0, 1.0, 0.0 ...], 2 to [0.0, 0.0, 1.0 ...]\n",
    "    labels = (np.arange(num_labels) == labels[:,None]).astype(np.float32)\n",
    "    return dataset, labels\n",
    "\n",
    "train_dataset, train_labels = reformat(train_dataset, train_labels)\n",
    "valid_dataset, valid_labels = reformat(valid_dataset, valid_labels)\n",
    "test_dataset, test_labels = reformat(test_dataset, test_labels)\n",
    "print('Training set', train_dataset.shape, train_labels.shape)\n",
    "print('Validation set', valid_dataset.shape, valid_labels.shape)\n",
    "print('Test set', test_dataset.shape, test_labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "cellView": "both",
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "RajPLaL_ZW6w"
   },
   "outputs": [],
   "source": [
    "def accuracy(predictions, labels):\n",
    "    return (100.0 * np.sum(np.argmax(predictions, 1) == np.argmax(labels, 1)) / predictions.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "sgLbUAQ1CW-1"
   },
   "source": [
    "---\n",
    "Problem 1\n",
    "---------\n",
    "\n",
    "Introduce and tune L2 regularization for both logistic and neural network models. Remember that L2 amounts to adding a penalty on the norm of the weights to the loss. In TensorFlow, you can compute the L2 loss for a tensor `t` using `nn.l2_loss(t)`. The right amount of regularization should improve your validation / test accuracy.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-5-a500a22637fa>:21: softmax_cross_entropy_with_logits (from tensorflow.python.ops.nn_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "\n",
      "Future major versions of TensorFlow will allow gradients to flow\n",
      "into the labels input on backprop by default.\n",
      "\n",
      "See @{tf.nn.softmax_cross_entropy_with_logits_v2}.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "batch_size = 128\n",
    "\n",
    "with tf.device('/CPU:0'):\n",
    "    graph = tf.Graph()\n",
    "    with graph.as_default():\n",
    "\n",
    "        # Input data. For the training data, we use a placeholder that will be fed\n",
    "        # at run time with a training minibatch.\n",
    "        tf_train_dataset = tf.placeholder(tf.float32, shape=(batch_size, image_size * image_size))\n",
    "        tf_train_labels = tf.placeholder(tf.float32, shape=(batch_size, num_labels))\n",
    "        tf_valid_dataset = tf.constant(valid_dataset)\n",
    "        tf_test_dataset = tf.constant(test_dataset)\n",
    "        beta_regul = tf.placeholder(tf.float32)\n",
    "\n",
    "        # Variables.\n",
    "        weights = tf.Variable(tf.truncated_normal([image_size * image_size, num_labels]))\n",
    "        biases = tf.Variable(tf.zeros([num_labels]))\n",
    "\n",
    "        # Training computation.\n",
    "        logits = tf.matmul(tf_train_dataset, weights) + biases\n",
    "        loss = tf.reduce_mean( tf.nn.softmax_cross_entropy_with_logits(labels=tf_train_labels, logits=logits)\n",
    "                             ) + beta_regul * tf.nn.l2_loss(weights)\n",
    "\n",
    "        # Optimizer.\n",
    "        optimizer = tf.train.GradientDescentOptimizer(0.5).minimize(loss)\n",
    "\n",
    "        # Predictions for the training, validation, and test data.\n",
    "        train_prediction = tf.nn.softmax(logits)\n",
    "        valid_prediction = tf.nn.softmax(tf.matmul(tf_valid_dataset, weights) + biases)\n",
    "        test_prediction = tf.nn.softmax(tf.matmul(tf_test_dataset, weights) + biases)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialized\n",
      "Minibatch loss at step 0: 49.532230\n",
      "Minibatch accuracy: 7.0%\n",
      "Validation accuracy: 12.3%\n",
      "Minibatch loss at step 500: 0.817138\n",
      "Minibatch accuracy: 85.9%\n",
      "Validation accuracy: 81.6%\n",
      "Minibatch loss at step 1000: 0.702110\n",
      "Minibatch accuracy: 82.8%\n",
      "Validation accuracy: 81.5%\n",
      "Minibatch loss at step 1500: 0.715258\n",
      "Minibatch accuracy: 82.0%\n",
      "Validation accuracy: 80.1%\n",
      "Minibatch loss at step 2000: 0.714621\n",
      "Minibatch accuracy: 83.6%\n",
      "Validation accuracy: 81.2%\n",
      "Minibatch loss at step 2500: 0.827449\n",
      "Minibatch accuracy: 81.2%\n",
      "Validation accuracy: 81.4%\n",
      "Minibatch loss at step 3000: 0.895790\n",
      "Minibatch accuracy: 80.5%\n",
      "Validation accuracy: 81.5%\n",
      "Test accuracy: 88.5%\n"
     ]
    }
   ],
   "source": [
    "num_steps = 3001\n",
    "\n",
    "# config = tf.ConfigProto(device_count = {'GPU': 1})\n",
    "\n",
    "with tf.Session(graph=graph) as session:  # , config=config\n",
    "    tf.global_variables_initializer().run()\n",
    "    print(\"Initialized\")\n",
    "    for step in range(num_steps):\n",
    "            # Pick an offset within the training data, which has been randomized.\n",
    "            # Note: we could use better randomization across epochs.\n",
    "            offset = (step * batch_size) % (train_labels.shape[0] - batch_size)\n",
    "            # Generate a minibatch.\n",
    "            batch_data = train_dataset[offset:(offset + batch_size), :]\n",
    "            batch_labels = train_labels[offset:(offset + batch_size), :]\n",
    "            # Prepare a dictionary telling the session where to feed the minibatch.\n",
    "            # The key of the dictionary is the placeholder node of the graph to be fed,\n",
    "            # and the value is the numpy array to feed to it.\n",
    "            feed_dict = {tf_train_dataset : batch_data, tf_train_labels : batch_labels, beta_regul : 0.01}\n",
    "            _, l, predictions = session.run([optimizer, loss, train_prediction], feed_dict=feed_dict)\n",
    "            if (step % 500 == 0):\n",
    "                print(\"Minibatch loss at step %d: %f\" % (step, l))\n",
    "                print(\"Minibatch accuracy: %.1f%%\" % accuracy(predictions, batch_labels))\n",
    "                print(\"Validation accuracy: %.1f%%\" % accuracy(valid_prediction.eval(), valid_labels))\n",
    "    print(\"Test accuracy: %.1f%%\" % accuracy(test_prediction.eval(), test_labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The L2 regularization introduces a new meta parameter that should be tuned. Since I do not have any idea of what should be the right value for this meta parameter, I will plot the accuracy by the meta parameter value (in a logarithmic scale)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regul_values = [pow(10, i) for i in np.arange(-4, -2, 0.1)]\n",
    "accuracy_val = []\n",
    "\n",
    "for beta in regul_values:\n",
    "    with tf.Session(graph=graph) as session:\n",
    "        tf.global_variables_initializer().run()\n",
    "        print(\"Initialized for reg = {0}\".format(beta))\n",
    "        for step in range(num_steps):\n",
    "                offset = (step * batch_size) % (train_labels.shape[0] - batch_size)\n",
    "                batch_data = train_dataset[offset:(offset + batch_size), :]\n",
    "                batch_labels = train_labels[offset:(offset + batch_size), :]\n",
    "                feed_dict = {tf_train_dataset : batch_data, tf_train_labels : batch_labels, beta_regul : beta}\n",
    "                _, l, predictions = session.run([optimizer, loss, train_prediction], feed_dict=feed_dict)\n",
    "        accuracy_val.append(accuracy(test_prediction.eval(), test_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.semilogx(regul_values, accuracy_val)\n",
    "plt.grid(True)\n",
    "plt.title('Test accuracy by regularization (logistic)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(regul_values, accuracy_val)\n",
    "plt.grid(True)\n",
    "plt.title('Test accuracy by regularization (logistic)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see if the same technique will improve the prediction of the 1-layer neural network:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 128\n",
    "\n",
    "graph = tf.Graph()\n",
    "with graph.as_default():\n",
    "\n",
    "    # Input data. For the training data, we use a placeholder that will be fed\n",
    "    # at run time with a training minibatch.\n",
    "    tf_train_dataset = tf.placeholder(tf.float32, shape=(batch_size, image_size * image_size))\n",
    "    tf_train_labels = tf.placeholder(tf.float32, shape=(batch_size, num_labels))\n",
    "    tf_valid_dataset = tf.constant(valid_dataset)\n",
    "    tf_test_dataset = tf.constant(test_dataset)\n",
    "    beta_regul = tf.placeholder(tf.float32)\n",
    "    \n",
    "    # Variables.\n",
    "    hidden_layer_size = 1024\n",
    "    hidden_weights = tf.Variable(tf.truncated_normal([image_size * image_size, hidden_layer_size]))\n",
    "    hidden_biases = tf.Variable(tf.zeros([hidden_layer_size]))\n",
    "    \n",
    "    hidden_logits = tf.nn.relu(tf.matmul(tf_train_dataset, hidden_weights) + hidden_biases)\n",
    "\n",
    "    # Variables.\n",
    "    weights = tf.Variable(tf.truncated_normal([hidden_layer_size, num_labels]))\n",
    "    biases = tf.Variable(tf.zeros([num_labels]))\n",
    "\n",
    "    # Training computation.\n",
    "    logits = tf.matmul(hidden_logits, weights) + biases\n",
    "    loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(labels=tf_train_labels, logits=logits))+ \\\n",
    "      beta_regul * (tf.nn.l2_loss(hidden_weights) + tf.nn.l2_loss(weights))\n",
    "\n",
    "    # Optimizer.\n",
    "    optimizer = tf.train.GradientDescentOptimizer(0.5).minimize(loss)\n",
    "\n",
    "    # Predictions for the training, validation, and test data.\n",
    "    train_prediction = tf.nn.softmax(logits)\n",
    "    hidden_valid_weights = tf.nn.relu(tf.matmul(tf_valid_dataset, hidden_weights) + hidden_biases)\n",
    "    valid_prediction = tf.nn.softmax(tf.matmul(hidden_valid_weights, weights) + biases)\n",
    "    hidden_test_weights = tf.nn.relu(tf.matmul(tf_test_dataset, hidden_weights) + hidden_biases)\n",
    "    test_prediction = tf.nn.softmax(tf.matmul(hidden_test_weights, weights) + biases)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialized\n",
      "Minibatch loss at step 0: 672.436646\n",
      "Minibatch accuracy: 11.7%\n",
      "Validation accuracy: 29.5%\n",
      "Minibatch loss at step 500: 201.751068\n",
      "Minibatch accuracy: 79.7%\n",
      "Validation accuracy: 79.8%\n",
      "Minibatch loss at step 1000: 113.840797\n",
      "Minibatch accuracy: 84.4%\n",
      "Validation accuracy: 82.2%\n",
      "Minibatch loss at step 1500: 68.788177\n",
      "Minibatch accuracy: 78.9%\n",
      "Validation accuracy: 83.2%\n",
      "Minibatch loss at step 2000: 41.282558\n",
      "Minibatch accuracy: 87.5%\n",
      "Validation accuracy: 84.7%\n",
      "Minibatch loss at step 2500: 25.300739\n",
      "Minibatch accuracy: 85.2%\n",
      "Validation accuracy: 85.8%\n",
      "Minibatch loss at step 3000: 15.591755\n",
      "Minibatch accuracy: 86.7%\n",
      "Validation accuracy: 87.1%\n",
      "Test accuracy: 93.2%\n"
     ]
    }
   ],
   "source": [
    "num_steps = 3001\n",
    "\n",
    "with tf.Session(graph=graph) as session:\n",
    "    tf.global_variables_initializer().run()\n",
    "    print(\"Initialized\")\n",
    "    for step in range(num_steps):\n",
    "            # Pick an offset within the training data, which has been randomized.\n",
    "            # Note: we could use better randomization across epochs.\n",
    "            offset = (step * batch_size) % (train_labels.shape[0] - batch_size)\n",
    "            # Generate a minibatch.\n",
    "            batch_data = train_dataset[offset:(offset + batch_size), :]\n",
    "            batch_labels = train_labels[offset:(offset + batch_size), :]\n",
    "            # Prepare a dictionary telling the session where to feed the minibatch.\n",
    "            # The key of the dictionary is the placeholder node of the graph to be fed,\n",
    "            # and the value is the numpy array to feed to it.\n",
    "            feed_dict = {tf_train_dataset : batch_data, tf_train_labels : batch_labels, beta_regul : 0.001 }\n",
    "            _, l, predictions = session.run([optimizer, loss, train_prediction], feed_dict=feed_dict)\n",
    "            if (step % 500 == 0):\n",
    "                print(\"Minibatch loss at step %d: %f\" % (step, l))\n",
    "                print(\"Minibatch accuracy: %.1f%%\" % accuracy(predictions, batch_labels))\n",
    "                print(\"Validation accuracy: %.1f%%\" % accuracy(valid_prediction.eval(), valid_labels))\n",
    "    print(\"Test accuracy: %.1f%%\" % accuracy(test_prediction.eval(), test_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialized for reg = 0.0001\n",
      "Initialized for reg = 0.00012589254117941674\n",
      "Initialized for reg = 0.00015848931924611142\n",
      "Initialized for reg = 0.0001995262314968881\n",
      "Initialized for reg = 0.0002511886431509582\n",
      "Initialized for reg = 0.00031622776601683826\n",
      "Initialized for reg = 0.00039810717055349773\n",
      "Initialized for reg = 0.000501187233627273\n",
      "Initialized for reg = 0.0006309573444801943\n",
      "Initialized for reg = 0.0007943282347242829\n",
      "Initialized for reg = 0.001000000000000002\n",
      "Initialized for reg = 0.00125892541179417\n",
      "Initialized for reg = 0.0015848931924611173\n",
      "Initialized for reg = 0.001995262314968885\n",
      "Initialized for reg = 0.0025118864315095872\n",
      "Initialized for reg = 0.003162277660168389\n",
      "Initialized for reg = 0.0039810717055349856\n",
      "Initialized for reg = 0.00501187233627274\n",
      "Initialized for reg = 0.006309573444801955\n",
      "Initialized for reg = 0.007943282347242847\n"
     ]
    }
   ],
   "source": [
    "regul_values = [pow(10, i) for i in np.arange(-4, -2, 0.1)]\n",
    "accuracy_val = []\n",
    "\n",
    "for beta in regul_values:\n",
    "    with tf.Session(graph=graph) as session:\n",
    "        tf.global_variables_initializer().run()\n",
    "        print(\"Initialized for reg = {0}\".format(beta))\n",
    "        for step in range(num_steps):\n",
    "                offset = (step * batch_size) % (train_labels.shape[0] - batch_size)\n",
    "                batch_data = train_dataset[offset:(offset + batch_size), :]\n",
    "                batch_labels = train_labels[offset:(offset + batch_size), :]\n",
    "                feed_dict = {tf_train_dataset : batch_data, tf_train_labels : batch_labels, beta_regul : beta}\n",
    "                _, l, predictions = session.run([optimizer, loss, train_prediction], feed_dict=feed_dict)\n",
    "        accuracy_val.append(accuracy(test_prediction.eval(), test_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.semilogx(regul_values, accuracy_val)\n",
    "plt.grid(True)\n",
    "plt.title('Test accuracy by regularization (logistic)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "na8xX2yHZzNF"
   },
   "source": [
    "---\n",
    "Problem 2\n",
    "---------\n",
    "Let's demonstrate an extreme case of overfitting. Restrict your training data to just a few batches. What happens?\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 128\n",
    "num_hidden_nodes = 1024\n",
    "\n",
    "graph = tf.Graph()\n",
    "with graph.as_default():\n",
    "\n",
    "    # Input data. For the training data, we use a placeholder that will be fed\n",
    "    # at run time with a training minibatch.\n",
    "    tf_train_dataset = tf.placeholder(tf.float32, shape=(batch_size, image_size * image_size))\n",
    "    tf_train_labels = tf.placeholder(tf.float32, shape=(batch_size, num_labels))\n",
    "    tf_valid_dataset = tf.constant(valid_dataset)\n",
    "    tf_test_dataset = tf.constant(test_dataset)\n",
    "    beta_regul = tf.placeholder(tf.float32)\n",
    "\n",
    "    # Variables.\n",
    "    weights1 = tf.Variable(\n",
    "    tf.truncated_normal([image_size * image_size, num_hidden_nodes]))\n",
    "    biases1 = tf.Variable(tf.zeros([num_hidden_nodes]))\n",
    "    weights2 = tf.Variable(tf.truncated_normal([num_hidden_nodes, num_labels]))\n",
    "    biases2 = tf.Variable(tf.zeros([num_labels]))\n",
    "\n",
    "    # Training computation.\n",
    "    lay1_train = tf.nn.relu(tf.matmul(tf_train_dataset, weights1) + biases1)\n",
    "    logits = tf.matmul(lay1_train, weights2) + biases2\n",
    "    loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(labels=tf_train_labels, logits=logits))\n",
    "\n",
    "    # Optimizer.\n",
    "    optimizer = tf.train.GradientDescentOptimizer(0.5).minimize(loss)\n",
    "\n",
    "    # Predictions for the training, validation, and test data.\n",
    "    train_prediction = tf.nn.softmax(logits)\n",
    "    lay1_valid = tf.nn.relu(tf.matmul(tf_valid_dataset, weights1) + biases1)\n",
    "    valid_prediction = tf.nn.softmax(tf.matmul(lay1_valid, weights2) + biases2)\n",
    "    lay1_test = tf.nn.relu(tf.matmul(tf_test_dataset, weights1) + biases1)\n",
    "    test_prediction = tf.nn.softmax(tf.matmul(lay1_test, weights2) + biases2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\util\\tf_should_use.py:118: initialize_all_variables (from tensorflow.python.ops.variables) is deprecated and will be removed after 2017-03-02.\n",
      "Instructions for updating:\n",
      "Use `tf.global_variables_initializer` instead.\n",
      "Initialized\n",
      "Minibatch loss at step 0: 361.365265\n",
      "Minibatch accuracy: 8.6%\n",
      "Validation accuracy: 30.1%\n",
      "Minibatch loss at step 2: 1877.648071\n",
      "Minibatch accuracy: 29.7%\n",
      "Validation accuracy: 39.6%\n",
      "Minibatch loss at step 4: 348.303314\n",
      "Minibatch accuracy: 62.5%\n",
      "Validation accuracy: 60.3%\n",
      "Minibatch loss at step 6: 104.857864\n",
      "Minibatch accuracy: 71.1%\n",
      "Validation accuracy: 69.5%\n",
      "Minibatch loss at step 8: 82.090813\n",
      "Minibatch accuracy: 82.8%\n",
      "Validation accuracy: 72.0%\n",
      "Minibatch loss at step 10: 27.042318\n",
      "Minibatch accuracy: 89.1%\n",
      "Validation accuracy: 73.0%\n",
      "Minibatch loss at step 12: 22.067543\n",
      "Minibatch accuracy: 92.2%\n",
      "Validation accuracy: 74.8%\n",
      "Minibatch loss at step 14: 17.057352\n",
      "Minibatch accuracy: 97.7%\n",
      "Validation accuracy: 74.4%\n",
      "Minibatch loss at step 16: 2.680328\n",
      "Minibatch accuracy: 98.4%\n",
      "Validation accuracy: 76.3%\n",
      "Minibatch loss at step 18: 8.165939\n",
      "Minibatch accuracy: 97.7%\n",
      "Validation accuracy: 75.2%\n",
      "Minibatch loss at step 20: 24.204243\n",
      "Minibatch accuracy: 97.7%\n",
      "Validation accuracy: 74.2%\n",
      "Minibatch loss at step 22: 0.000000\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 75.5%\n",
      "Minibatch loss at step 24: 7.744218\n",
      "Minibatch accuracy: 99.2%\n",
      "Validation accuracy: 75.6%\n",
      "Minibatch loss at step 26: 8.208218\n",
      "Minibatch accuracy: 99.2%\n",
      "Validation accuracy: 73.5%\n",
      "Minibatch loss at step 28: 0.000000\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 75.6%\n",
      "Minibatch loss at step 30: 6.820406\n",
      "Minibatch accuracy: 99.2%\n",
      "Validation accuracy: 75.6%\n",
      "Minibatch loss at step 32: 8.420660\n",
      "Minibatch accuracy: 99.2%\n",
      "Validation accuracy: 73.6%\n",
      "Minibatch loss at step 34: 0.000000\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 75.6%\n",
      "Minibatch loss at step 36: 5.933033\n",
      "Minibatch accuracy: 99.2%\n",
      "Validation accuracy: 75.6%\n",
      "Minibatch loss at step 38: 8.657425\n",
      "Minibatch accuracy: 99.2%\n",
      "Validation accuracy: 73.7%\n",
      "Minibatch loss at step 40: 0.000000\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 75.6%\n",
      "Minibatch loss at step 42: 5.080997\n",
      "Minibatch accuracy: 99.2%\n",
      "Validation accuracy: 75.5%\n",
      "Minibatch loss at step 44: 8.880411\n",
      "Minibatch accuracy: 99.2%\n",
      "Validation accuracy: 73.7%\n",
      "Minibatch loss at step 46: 0.000000\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 75.6%\n",
      "Minibatch loss at step 48: 4.267316\n",
      "Minibatch accuracy: 99.2%\n",
      "Validation accuracy: 75.5%\n",
      "Minibatch loss at step 50: 9.061411\n",
      "Minibatch accuracy: 99.2%\n",
      "Validation accuracy: 73.8%\n",
      "Minibatch loss at step 52: 0.000000\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 75.1%\n",
      "Minibatch loss at step 54: 0.000001\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 75.4%\n",
      "Minibatch loss at step 56: 1.745894\n",
      "Minibatch accuracy: 99.2%\n",
      "Validation accuracy: 73.2%\n",
      "Minibatch loss at step 58: 0.000000\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 75.2%\n",
      "Minibatch loss at step 60: 0.000002\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 75.3%\n",
      "Minibatch loss at step 62: 0.000203\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 75.3%\n",
      "Minibatch loss at step 64: 0.000000\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 75.3%\n",
      "Minibatch loss at step 66: 0.000002\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 75.3%\n",
      "Minibatch loss at step 68: 0.000002\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 75.3%\n",
      "Minibatch loss at step 70: 0.000000\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 75.3%\n",
      "Minibatch loss at step 72: 0.000001\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 75.3%\n",
      "Minibatch loss at step 74: 0.000002\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 75.3%\n",
      "Minibatch loss at step 76: 0.000000\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 75.3%\n",
      "Minibatch loss at step 78: 0.000001\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 75.3%\n",
      "Minibatch loss at step 80: 0.000002\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 75.3%\n",
      "Minibatch loss at step 82: 0.000000\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 75.3%\n",
      "Minibatch loss at step 84: 0.000001\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 75.3%\n",
      "Minibatch loss at step 86: 0.000002\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 75.3%\n",
      "Minibatch loss at step 88: 0.000000\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 75.3%\n",
      "Minibatch loss at step 90: 0.000001\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 75.3%\n",
      "Minibatch loss at step 92: 0.000002\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 75.3%\n",
      "Minibatch loss at step 94: 0.000000\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 75.3%\n",
      "Minibatch loss at step 96: 0.000001\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 75.3%\n",
      "Minibatch loss at step 98: 0.000002\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 75.3%\n",
      "Minibatch loss at step 100: 0.000000\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 75.3%\n",
      "Test accuracy: 82.3%\n"
     ]
    }
   ],
   "source": [
    "num_steps = 101\n",
    "num_batches = 3\n",
    "\n",
    "with tf.Session(graph=graph) as session:\n",
    "    tf.initialize_all_variables().run()\n",
    "    print(\"Initialized\")\n",
    "    for step in range(num_steps):\n",
    "        # Pick an offset within the training data, which has been randomized.\n",
    "        # Note: we could use better randomization across epochs.\n",
    "        #offset = (step * batch_size) % (train_labels.shape[0] - batch_size)\n",
    "        offset = ((step % num_batches) * batch_size) % (train_labels.shape[0] - batch_size)\n",
    "        # Generate a minibatch.\n",
    "        batch_data = train_dataset[offset:(offset + batch_size), :]\n",
    "        batch_labels = train_labels[offset:(offset + batch_size), :]\n",
    "        # Prepare a dictionary telling the session where to feed the minibatch.\n",
    "        # The key of the dictionary is the placeholder node of the graph to be fed,\n",
    "        # and the value is the numpy array to feed to it.\n",
    "        feed_dict = {tf_train_dataset : batch_data, tf_train_labels : batch_labels}\n",
    "        _, l, predictions = session.run([optimizer, loss, train_prediction], feed_dict=feed_dict)\n",
    "        if (step % 2 == 0):\n",
    "            print(\"Minibatch loss at step %d: %f\" % (step, l))\n",
    "            print(\"Minibatch accuracy: %.1f%%\" % accuracy(predictions, batch_labels))\n",
    "            print(\"Validation accuracy: %.1f%%\" % accuracy(valid_prediction.eval(), valid_labels))\n",
    "    print(\"Test accuracy: %.1f%%\" % accuracy(test_prediction.eval(), test_labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ww3SCBUdlkRc"
   },
   "source": [
    "---\n",
    "Problem 3\n",
    "---------\n",
    "Introduce Dropout on the hidden layer of the neural network. Remember: Dropout should only be introduced during training, not evaluation, otherwise your evaluation results would be stochastic as well. TensorFlow provides `nn.dropout()` for that, but you have to make sure it's only inserted during training.\n",
    "\n",
    "What happens to our extreme overfitting case?\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 128\n",
    "\n",
    "graph = tf.Graph()\n",
    "with graph.as_default():\n",
    "\n",
    "    # Input data. For the training data, we use a placeholder that will be fed\n",
    "    # at run time with a training minibatch.\n",
    "    tf_train_dataset = tf.placeholder(tf.float32, shape=(batch_size, image_size * image_size))\n",
    "    tf_train_labels = tf.placeholder(tf.float32, shape=(batch_size, num_labels))\n",
    "    tf_valid_dataset = tf.constant(valid_dataset)\n",
    "    tf_test_dataset = tf.constant(test_dataset)\n",
    "    \n",
    "    # Variables.\n",
    "    hidden_layer_size = 1024\n",
    "    hidden_weights = tf.Variable(tf.truncated_normal([image_size * image_size, hidden_layer_size]))\n",
    "    hidden_biases = tf.Variable(tf.zeros([hidden_layer_size]))\n",
    "    \n",
    "    hidden_logits = tf.nn.relu(tf.matmul(tf_train_dataset, hidden_weights) + hidden_biases)\n",
    "    \n",
    "    drop1 = tf.nn.dropout(hidden_logits, 0.5)\n",
    "\n",
    "    # Variables.\n",
    "    weights = tf.Variable(tf.truncated_normal([hidden_layer_size, num_labels]))\n",
    "    biases = tf.Variable(tf.zeros([num_labels]))\n",
    "\n",
    "    # Training computation.\n",
    "    logits = tf.matmul(drop1, weights) + biases\n",
    "    loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(labels=tf_train_labels, logits=logits))\n",
    "\n",
    "    # Optimizer.\n",
    "    optimizer = tf.train.GradientDescentOptimizer(0.5).minimize(loss)\n",
    "\n",
    "    # Predictions for the training, validation, and test data.\n",
    "    train_prediction = tf.nn.softmax(logits)\n",
    "    hidden_valid_weights = tf.nn.relu(tf.matmul(tf_valid_dataset, hidden_weights) + hidden_biases)\n",
    "    valid_prediction = tf.nn.softmax(tf.matmul(hidden_valid_weights, weights) + biases)\n",
    "    hidden_test_weights = tf.nn.relu(tf.matmul(tf_test_dataset, hidden_weights) + hidden_biases)\n",
    "    test_prediction = tf.nn.softmax(tf.matmul(hidden_test_weights, weights) + biases)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialized\n",
      "Minibatch loss at step 0: 473.352966\n",
      "Minibatch accuracy: 8.6%\n",
      "Validation accuracy: 32.2%\n",
      "Minibatch loss at step 500: 35.663059\n",
      "Minibatch accuracy: 80.5%\n",
      "Validation accuracy: 80.6%\n",
      "Minibatch loss at step 1000: 18.194447\n",
      "Minibatch accuracy: 67.2%\n",
      "Validation accuracy: 79.6%\n",
      "Minibatch loss at step 1500: 13.711524\n",
      "Minibatch accuracy: 68.8%\n",
      "Validation accuracy: 78.9%\n",
      "Minibatch loss at step 2000: 12.064564\n",
      "Minibatch accuracy: 73.4%\n",
      "Validation accuracy: 78.8%\n",
      "Minibatch loss at step 2500: 14.038031\n",
      "Minibatch accuracy: 72.7%\n",
      "Validation accuracy: 79.7%\n",
      "Minibatch loss at step 3000: 6.123107\n",
      "Minibatch accuracy: 71.9%\n",
      "Validation accuracy: 79.6%\n",
      "Minibatch loss at step 3500: 8.254789\n",
      "Minibatch accuracy: 69.5%\n",
      "Validation accuracy: 79.6%\n",
      "Minibatch loss at step 4000: 4.313130\n",
      "Minibatch accuracy: 68.8%\n",
      "Validation accuracy: 79.8%\n",
      "Minibatch loss at step 4500: 2.822562\n",
      "Minibatch accuracy: 69.5%\n",
      "Validation accuracy: 80.0%\n",
      "Minibatch loss at step 5000: 1.729514\n",
      "Minibatch accuracy: 81.2%\n",
      "Validation accuracy: 80.8%\n",
      "Minibatch loss at step 5500: 2.988463\n",
      "Minibatch accuracy: 78.1%\n",
      "Validation accuracy: 81.1%\n",
      "Minibatch loss at step 6000: 1.829571\n",
      "Minibatch accuracy: 75.8%\n",
      "Validation accuracy: 80.9%\n",
      "Minibatch loss at step 6500: 2.159131\n",
      "Minibatch accuracy: 82.0%\n",
      "Validation accuracy: 80.9%\n",
      "Minibatch loss at step 7000: 8.726856\n",
      "Minibatch accuracy: 72.7%\n",
      "Validation accuracy: 81.0%\n",
      "Minibatch loss at step 7500: 4.214888\n",
      "Minibatch accuracy: 78.1%\n",
      "Validation accuracy: 81.6%\n",
      "Minibatch loss at step 8000: 1.920614\n",
      "Minibatch accuracy: 79.7%\n",
      "Validation accuracy: 80.9%\n",
      "Minibatch loss at step 8500: 1.751908\n",
      "Minibatch accuracy: 78.1%\n",
      "Validation accuracy: 81.2%\n",
      "Minibatch loss at step 9000: 1.196449\n",
      "Minibatch accuracy: 75.8%\n",
      "Validation accuracy: 81.4%\n",
      "Test accuracy: 88.9%\n"
     ]
    }
   ],
   "source": [
    "num_steps = 9001\n",
    "\n",
    "with tf.Session(graph=graph) as session:\n",
    "    tf.initialize_all_variables().run()\n",
    "    print(\"Initialized\")\n",
    "    for step in range(num_steps):\n",
    "        # Pick an offset within the training data, which has been randomized.\n",
    "        # Note: we could use better randomization across epochs.\n",
    "        offset = (step * batch_size) % (train_labels.shape[0] - batch_size)\n",
    "        # Generate a minibatch.\n",
    "        batch_data = train_dataset[offset:(offset + batch_size), :]\n",
    "        batch_labels = train_labels[offset:(offset + batch_size), :]\n",
    "        # Prepare a dictionary telling the session where to feed the minibatch.\n",
    "        # The key of the dictionary is the placeholder node of the graph to be fed,\n",
    "        # and the value is the numpy array to feed to it.\n",
    "        feed_dict = {tf_train_dataset : batch_data, tf_train_labels : batch_labels}\n",
    "        _, l, predictions = session.run(\n",
    "          [optimizer, loss, train_prediction], feed_dict=feed_dict)\n",
    "        if (step % 500 == 0):\n",
    "            print(\"Minibatch loss at step %d: %f\" % (step, l))\n",
    "            print(\"Minibatch accuracy: %.1f%%\" % accuracy(predictions, batch_labels))\n",
    "            print(\"Validation accuracy: %.1f%%\" % accuracy(valid_prediction.eval(), valid_labels))\n",
    "    print(\"Test accuracy: %.1f%%\" % accuracy(test_prediction.eval(), test_labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first conclusion is that 100% of accuracy on the minibatches is more difficult achieved or to keep. As a result, the test accuracy is improved by 6%, the final net is more capable of generalization."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "-b1hTz3VWZjw"
   },
   "source": [
    "---\n",
    "Problem 4\n",
    "---------\n",
    "\n",
    "Try to get the best performance you can using a multi-layer model! The best reported test accuracy using a deep network is [97.1%](http://yaroslavvb.blogspot.com/2011/09/notmnist-dataset.html?showComment=1391023266211#c8758720086795711595).\n",
    "\n",
    "One avenue you can explore is to add multiple layers.\n",
    "\n",
    "Another one is to use learning rate decay:\n",
    "\n",
    "    global_step = tf.Variable(0)  # count the number of steps taken.\n",
    "    learning_rate = tf.train.exponential_decay(0.5, global_step, ...)\n",
    "    optimizer = tf.train.GradientDescentOptimizer(learning_rate).minimize(loss, global_step=global_step)\n",
    " \n",
    " ---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's do a first try with 2 layers. Note how the parameters are initialized, compared to the previous cases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 128\n",
    "num_hidden_nodes1 = 1024\n",
    "num_hidden_nodes2 = 100\n",
    "beta_regul = 1e-3\n",
    "\n",
    "graph = tf.Graph()\n",
    "with graph.as_default():\n",
    "\n",
    "    # Input data. For the training data, we use a placeholder that will be fed\n",
    "    # at run time with a training minibatch.\n",
    "    tf_train_dataset = tf.placeholder(tf.float32, shape=(batch_size, image_size * image_size))\n",
    "    tf_train_labels = tf.placeholder(tf.float32, shape=(batch_size, num_labels))\n",
    "    tf_valid_dataset = tf.constant(valid_dataset)\n",
    "    tf_test_dataset = tf.constant(test_dataset)\n",
    "    global_step = tf.Variable(0)\n",
    "    \n",
    "    # Variables.\n",
    "    weights1 = tf.Variable(tf.truncated_normal([image_size * image_size, num_hidden_nodes1],\n",
    "        stddev=np.sqrt(2.0 / (image_size * image_size))))\n",
    "    biases1 = tf.Variable(tf.zeros([num_hidden_nodes1]))\n",
    "    \n",
    "    weights2 = tf.Variable(tf.truncated_normal([num_hidden_nodes1, num_hidden_nodes2],\n",
    "        stddev=np.sqrt(2.0 / num_hidden_nodes1 )))\n",
    "    biases2 = tf.Variable(tf.zeros([num_hidden_nodes2]))\n",
    "    \n",
    "    weights3 = tf.Variable(tf.truncated_normal([num_hidden_nodes2, num_labels],\n",
    "        stddev=np.sqrt(2.0 / num_hidden_nodes2 )))\n",
    "    biases3 = tf.Variable(tf.zeros([num_labels]))\n",
    "    \n",
    "    train_lay1 = tf.nn.relu(tf.matmul(tf_train_dataset, weights1) + biases1)\n",
    "    train_lay2 = tf.nn.relu(tf.matmul(train_lay1, weights2) + biases2)\n",
    "    logits = tf.matmul(train_lay2, weights3) + biases3\n",
    "    \n",
    "    \n",
    "    loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(labels=tf_train_labels, logits=logits)) + \\\n",
    "      beta_regul * (tf.nn.l2_loss(weights1) + tf.nn.l2_loss(weights2) + tf.nn.l2_loss(weights3))\n",
    "    \n",
    "    # Optimizer.\n",
    "    learning_rate = tf.train.exponential_decay(0.5, global_step, 1000, 0.65, staircase=True)\n",
    "    optimizer = tf.train.GradientDescentOptimizer(learning_rate).minimize(loss, global_step=global_step)\n",
    "\n",
    "    # Predictions for the training, validation, and test data.\n",
    "    train_prediction = tf.nn.softmax(logits)\n",
    "    lay1_valid = tf.nn.relu(tf.matmul(tf_valid_dataset, weights1) + biases1)\n",
    "    lay2_valid = tf.nn.relu(tf.matmul(lay1_valid, weights2) + biases2)\n",
    "    valid_prediction = tf.nn.softmax(tf.matmul(lay2_valid, weights3) + biases3)\n",
    "    lay1_test = tf.nn.relu(tf.matmul(tf_test_dataset, weights1) + biases1)\n",
    "    lay2_test = tf.nn.relu(tf.matmul(lay1_test, weights2) + biases2)\n",
    "    test_prediction = tf.nn.softmax(tf.matmul(lay2_test, weights3) + biases3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialized\n",
      "Minibatch loss at step 0: 3.315536\n",
      "Minibatch accuracy: 9.4%\n",
      "Validation accuracy: 34.2%\n",
      "Minibatch loss at step 500: 0.950471\n",
      "Minibatch accuracy: 88.3%\n",
      "Validation accuracy: 85.8%\n",
      "Minibatch loss at step 1000: 0.756789\n",
      "Minibatch accuracy: 89.1%\n",
      "Validation accuracy: 87.4%\n",
      "Minibatch loss at step 1500: 0.657827\n",
      "Minibatch accuracy: 90.6%\n",
      "Validation accuracy: 88.0%\n",
      "Minibatch loss at step 2000: 0.562426\n",
      "Minibatch accuracy: 91.4%\n",
      "Validation accuracy: 88.4%\n",
      "Minibatch loss at step 2500: 0.502285\n",
      "Minibatch accuracy: 92.2%\n",
      "Validation accuracy: 88.4%\n",
      "Minibatch loss at step 3000: 0.595671\n",
      "Minibatch accuracy: 89.1%\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss at step 3500: 0.564126\n",
      "Minibatch accuracy: 89.8%\n",
      "Validation accuracy: 89.5%\n",
      "Minibatch loss at step 4000: 0.421736\n",
      "Minibatch accuracy: 93.8%\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss at step 4500: 0.549614\n",
      "Minibatch accuracy: 86.7%\n",
      "Validation accuracy: 90.0%\n",
      "Minibatch loss at step 5000: 0.482717\n",
      "Minibatch accuracy: 89.8%\n",
      "Validation accuracy: 90.2%\n",
      "Minibatch loss at step 5500: 0.482721\n",
      "Minibatch accuracy: 89.1%\n",
      "Validation accuracy: 90.3%\n",
      "Minibatch loss at step 6000: 0.398811\n",
      "Minibatch accuracy: 93.0%\n",
      "Validation accuracy: 90.2%\n",
      "Minibatch loss at step 6500: 0.434372\n",
      "Minibatch accuracy: 91.4%\n",
      "Validation accuracy: 90.3%\n",
      "Minibatch loss at step 7000: 0.477438\n",
      "Minibatch accuracy: 89.8%\n",
      "Validation accuracy: 90.4%\n",
      "Minibatch loss at step 7500: 0.499157\n",
      "Minibatch accuracy: 90.6%\n",
      "Validation accuracy: 90.4%\n",
      "Minibatch loss at step 8000: 0.429309\n",
      "Minibatch accuracy: 92.2%\n",
      "Validation accuracy: 90.6%\n",
      "Minibatch loss at step 8500: 0.434309\n",
      "Minibatch accuracy: 93.0%\n",
      "Validation accuracy: 90.6%\n",
      "Minibatch loss at step 9000: 0.468793\n",
      "Minibatch accuracy: 90.6%\n",
      "Validation accuracy: 90.5%\n",
      "Test accuracy: 95.7%\n"
     ]
    }
   ],
   "source": [
    "num_steps = 9001\n",
    "\n",
    "with tf.Session(graph=graph) as session:\n",
    "    tf.initialize_all_variables().run()\n",
    "    print(\"Initialized\")\n",
    "    for step in range(num_steps):\n",
    "        # Pick an offset within the training data, which has been randomized.\n",
    "        # Note: we could use better randomization across epochs.\n",
    "        offset = (step * batch_size) % (train_labels.shape[0] - batch_size)\n",
    "        # Generate a minibatch.\n",
    "        batch_data = train_dataset[offset:(offset + batch_size), :]\n",
    "        batch_labels = train_labels[offset:(offset + batch_size), :]\n",
    "        # Prepare a dictionary telling the session where to feed the minibatch.\n",
    "        # The key of the dictionary is the placeholder node of the graph to be fed,\n",
    "        # and the value is the numpy array to feed to it.\n",
    "        feed_dict = {tf_train_dataset : batch_data, tf_train_labels : batch_labels}\n",
    "        _, l, predictions = session.run(\n",
    "          [optimizer, loss, train_prediction], feed_dict=feed_dict)\n",
    "        if (step % 500 == 0):\n",
    "            print(\"Minibatch loss at step %d: %f\" % (step, l))\n",
    "            print(\"Minibatch accuracy: %.1f%%\" % accuracy(predictions, batch_labels))\n",
    "            print(\"Validation accuracy: %.1f%%\" % accuracy(valid_prediction.eval(), valid_labels))\n",
    "    print(\"Test accuracy: %.1f%%\" % accuracy(test_prediction.eval(), test_labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is getting really good. Let's try one layer deeper with dropouts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 128\n",
    "num_hidden_nodes1 = 1024\n",
    "num_hidden_nodes2 = 256\n",
    "num_hidden_nodes3 = 128\n",
    "keep_prob = 0.5\n",
    "\n",
    "graph = tf.Graph()\n",
    "with graph.as_default():\n",
    "\n",
    "    # Input data. For the training data, we use a placeholder that will be fed\n",
    "    # at run time with a training minibatch.\n",
    "    tf_train_dataset = tf.placeholder(tf.float32,shape=(batch_size, image_size * image_size))\n",
    "    tf_train_labels = tf.placeholder(tf.float32, shape=(batch_size, num_labels))\n",
    "    tf_valid_dataset = tf.constant(valid_dataset)\n",
    "    tf_test_dataset = tf.constant(test_dataset)\n",
    "    global_step = tf.Variable(0)\n",
    "\n",
    "    # Variables.\n",
    "    weights1 = tf.Variable(tf.truncated_normal([image_size * image_size, num_hidden_nodes1],stddev=np.sqrt(2.0 / (image_size * image_size))))\n",
    "    biases1 = tf.Variable(tf.zeros([num_hidden_nodes1]))\n",
    "    weights2 = tf.Variable(tf.truncated_normal([num_hidden_nodes1, num_hidden_nodes2], stddev=np.sqrt(2.0 / num_hidden_nodes1)))\n",
    "    biases2 = tf.Variable(tf.zeros([num_hidden_nodes2]))\n",
    "    weights3 = tf.Variable(tf.truncated_normal([num_hidden_nodes2, num_hidden_nodes3], stddev=np.sqrt(2.0 / num_hidden_nodes2)))\n",
    "    biases3 = tf.Variable(tf.zeros([num_hidden_nodes3]))\n",
    "    weights4 = tf.Variable(tf.truncated_normal([num_hidden_nodes3, num_labels], stddev=np.sqrt(2.0 / num_hidden_nodes3)))\n",
    "    biases4 = tf.Variable(tf.zeros([num_labels]))\n",
    "\n",
    "    # Training computation.\n",
    "    lay1_train = tf.nn.relu(tf.matmul(tf_train_dataset, weights1) + biases1)\n",
    "    lay2_train = tf.nn.relu(tf.matmul(lay1_train, weights2) + biases2)\n",
    "    lay3_train = tf.nn.relu(tf.matmul(lay2_train, weights3) + biases3)\n",
    "    logits = tf.matmul(lay3_train, weights4) + biases4\n",
    "    loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(labels=tf_train_labels, logits=logits))\n",
    "\n",
    "    # Optimizer.\n",
    "    learning_rate = tf.train.exponential_decay(0.5, global_step, 4000, 0.65, staircase=True)\n",
    "    optimizer = tf.train.GradientDescentOptimizer(learning_rate).minimize(loss, global_step=global_step)\n",
    "\n",
    "    # Predictions for the training, validation, and test data.\n",
    "    train_prediction = tf.nn.softmax(logits)\n",
    "    lay1_valid = tf.nn.relu(tf.matmul(tf_valid_dataset, weights1) + biases1)\n",
    "    lay2_valid = tf.nn.relu(tf.matmul(lay1_valid, weights2) + biases2)\n",
    "    lay3_valid = tf.nn.relu(tf.matmul(lay2_valid, weights3) + biases3)\n",
    "    valid_prediction = tf.nn.softmax(tf.matmul(lay3_valid, weights4) + biases4)\n",
    "    lay1_test = tf.nn.relu(tf.matmul(tf_test_dataset, weights1) + biases1)\n",
    "    lay2_test = tf.nn.relu(tf.matmul(lay1_test, weights2) + biases2)\n",
    "    lay3_test = tf.nn.relu(tf.matmul(lay2_test, weights3) + biases3)\n",
    "    test_prediction = tf.nn.softmax(tf.matmul(lay3_test, weights4) + biases4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialized\n",
      "Minibatch loss at step 0: 2.419557\n",
      "Minibatch accuracy: 10.9%\n",
      "Validation accuracy: 27.0%\n",
      "Minibatch loss at step 500: 0.374907\n",
      "Minibatch accuracy: 89.8%\n",
      "Validation accuracy: 86.2%\n",
      "Minibatch loss at step 1000: 0.336655\n",
      "Minibatch accuracy: 91.4%\n",
      "Validation accuracy: 88.0%\n",
      "Minibatch loss at step 1500: 0.343719\n",
      "Minibatch accuracy: 89.8%\n",
      "Validation accuracy: 88.3%\n",
      "Minibatch loss at step 2000: 0.307655\n",
      "Minibatch accuracy: 91.4%\n",
      "Validation accuracy: 88.4%\n",
      "Minibatch loss at step 2500: 0.257297\n",
      "Minibatch accuracy: 92.2%\n",
      "Validation accuracy: 88.6%\n",
      "Minibatch loss at step 3000: 0.365275\n",
      "Minibatch accuracy: 89.1%\n",
      "Validation accuracy: 89.7%\n",
      "Minibatch loss at step 3500: 0.324155\n",
      "Minibatch accuracy: 89.1%\n",
      "Validation accuracy: 89.4%\n",
      "Minibatch loss at step 4000: 0.205635\n",
      "Minibatch accuracy: 95.3%\n",
      "Validation accuracy: 89.5%\n",
      "Minibatch loss at step 4500: 0.292933\n",
      "Minibatch accuracy: 89.1%\n",
      "Validation accuracy: 90.4%\n",
      "Minibatch loss at step 5000: 0.274238\n",
      "Minibatch accuracy: 92.2%\n",
      "Validation accuracy: 90.1%\n",
      "Minibatch loss at step 5500: 0.234140\n",
      "Minibatch accuracy: 93.0%\n",
      "Validation accuracy: 90.3%\n",
      "Minibatch loss at step 6000: 0.186535\n",
      "Minibatch accuracy: 91.4%\n",
      "Validation accuracy: 90.5%\n",
      "Minibatch loss at step 6500: 0.224443\n",
      "Minibatch accuracy: 93.0%\n",
      "Validation accuracy: 90.5%\n",
      "Minibatch loss at step 7000: 0.216452\n",
      "Minibatch accuracy: 92.2%\n",
      "Validation accuracy: 90.3%\n",
      "Minibatch loss at step 7500: 0.214769\n",
      "Minibatch accuracy: 93.0%\n",
      "Validation accuracy: 90.7%\n",
      "Minibatch loss at step 8000: 0.176528\n",
      "Minibatch accuracy: 94.5%\n",
      "Validation accuracy: 90.4%\n",
      "Minibatch loss at step 8500: 0.160877\n",
      "Minibatch accuracy: 97.7%\n",
      "Validation accuracy: 90.9%\n",
      "Minibatch loss at step 9000: 0.195710\n",
      "Minibatch accuracy: 92.2%\n",
      "Validation accuracy: 90.9%\n",
      "Minibatch loss at step 9500: 0.115425\n",
      "Minibatch accuracy: 96.1%\n",
      "Validation accuracy: 90.8%\n",
      "Minibatch loss at step 10000: 0.100446\n",
      "Minibatch accuracy: 96.1%\n",
      "Validation accuracy: 90.7%\n",
      "Minibatch loss at step 10500: 0.213069\n",
      "Minibatch accuracy: 94.5%\n",
      "Validation accuracy: 91.3%\n",
      "Minibatch loss at step 11000: 0.073984\n",
      "Minibatch accuracy: 96.9%\n",
      "Validation accuracy: 91.0%\n",
      "Minibatch loss at step 11500: 0.075234\n",
      "Minibatch accuracy: 97.7%\n",
      "Validation accuracy: 91.0%\n",
      "Minibatch loss at step 12000: 0.056974\n",
      "Minibatch accuracy: 97.7%\n",
      "Validation accuracy: 90.9%\n",
      "Minibatch loss at step 12500: 0.077723\n",
      "Minibatch accuracy: 98.4%\n",
      "Validation accuracy: 91.2%\n",
      "Minibatch loss at step 13000: 0.169590\n",
      "Minibatch accuracy: 93.8%\n",
      "Validation accuracy: 91.1%\n",
      "Minibatch loss at step 13500: 0.053764\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 91.3%\n",
      "Minibatch loss at step 14000: 0.150134\n",
      "Minibatch accuracy: 94.5%\n",
      "Validation accuracy: 91.1%\n",
      "Minibatch loss at step 14500: 0.070545\n",
      "Minibatch accuracy: 98.4%\n",
      "Validation accuracy: 91.4%\n",
      "Minibatch loss at step 15000: 0.076109\n",
      "Minibatch accuracy: 97.7%\n",
      "Validation accuracy: 91.4%\n",
      "Minibatch loss at step 15500: 0.068033\n",
      "Minibatch accuracy: 96.9%\n",
      "Validation accuracy: 91.2%\n",
      "Minibatch loss at step 16000: 0.044283\n",
      "Minibatch accuracy: 99.2%\n",
      "Validation accuracy: 91.0%\n",
      "Minibatch loss at step 16500: 0.024097\n",
      "Minibatch accuracy: 99.2%\n",
      "Validation accuracy: 91.2%\n",
      "Minibatch loss at step 17000: 0.025388\n",
      "Minibatch accuracy: 99.2%\n",
      "Validation accuracy: 91.5%\n",
      "Minibatch loss at step 17500: 0.029274\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 91.2%\n",
      "Minibatch loss at step 18000: 0.061122\n",
      "Minibatch accuracy: 98.4%\n",
      "Validation accuracy: 91.3%\n",
      "Test accuracy: 96.4%\n"
     ]
    }
   ],
   "source": [
    "num_steps = 18001\n",
    "\n",
    "with tf.Session(graph=graph) as session:\n",
    "    tf.initialize_all_variables().run()\n",
    "    print(\"Initialized\")\n",
    "    for step in range(num_steps):\n",
    "        # Pick an offset within the training data, which has been randomized.\n",
    "        # Note: we could use better randomization across epochs.\n",
    "        offset = (step * batch_size) % (train_labels.shape[0] - batch_size)\n",
    "        # Generate a minibatch.\n",
    "        batch_data = train_dataset[offset:(offset + batch_size), :]\n",
    "        batch_labels = train_labels[offset:(offset + batch_size), :]\n",
    "        # Prepare a dictionary telling the session where to feed the minibatch.\n",
    "        # The key of the dictionary is the placeholder node of the graph to be fed,\n",
    "        # and the value is the numpy array to feed to it.\n",
    "        feed_dict = {tf_train_dataset : batch_data, tf_train_labels : batch_labels}\n",
    "        _, l, predictions = session.run(\n",
    "          [optimizer, loss, train_prediction], feed_dict=feed_dict)\n",
    "        if (step % 500 == 0):\n",
    "            print(\"Minibatch loss at step %d: %f\" % (step, l))\n",
    "            print(\"Minibatch accuracy: %.1f%%\" % accuracy(predictions, batch_labels))\n",
    "            print(\"Validation accuracy: %.1f%%\" % accuracy(valid_prediction.eval(), valid_labels))\n",
    "    print(\"Test accuracy: %.1f%%\" % accuracy(test_prediction.eval(), test_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "default_view": {},
   "name": "3_regularization.ipynb",
   "provenance": [],
   "version": "0.3.2",
   "views": {}
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
